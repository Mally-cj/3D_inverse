from Model.net2D import UNet, forward_model
import torch
from Model.utils import DIFFZ, tv_loss, wavelet_init, save_stage1_loss_data, save_stage2_loss_data, save_complete_training_loss
from scipy.signal.windows import gaussian
import pylops
from data_processor import SeismicDataProcessor
import numpy as np
import os
from visual_results import plot_sections_with_wells,plot_well_curves_seisvis
import threading
from functools import wraps
import pdb
from data_tools import run_in_thread

# device = torch.device("cuda:1" if torch.cuda.is_available() else "cpu")

##å‡†å¤‡æ•°æ®
# processor = SeismicDataProcessor(cache_dir='cache', device=device)
# test_loader, xy, shape3d, norm_params = processor.process_test_data(batch_size=100,patch_size=800)
# number_of_patches = len(xy)
# print(f"number_of_patches: {number_of_patches}")

@run_in_thread
def inference(model_path1=None,model_path2=None,folder_dir='logs/test',inference_device="cpu", config=None):
    print('æ–°å¼€çº¿ç¨‹æ‰§è¡Œæ¨ç†...')
    device = torch.device(inference_device)
    # inference_device = torch.device("cuda:1" if torch.cuda.is_available() else "cpu")
    processor = SeismicDataProcessor(cache_dir='cache', device=inference_device)
    test_loader, xy, shape3d, norm_params = processor.process_test_data(batch_size=500,patch_size=120)
    number_of_patches = len(xy)
    print(f"number_of_patches: {number_of_patches}")

    # é˜¶æ®µä¸€ï¼šForwardå»ºæ¨¡ç½‘ç»œï¼ˆå­æ³¢å­¦ä¹ ï¼‰
    forward_net = forward_model(nonlinearity=config['forward_nonlinearity']).to(device)
    forward_net.load_state_dict(torch.load(model_path1, map_location=device))
    forward_net.eval()
    

    # é˜¶æ®µäºŒï¼šåŠ è½½é¢„è®­ç»ƒæ¨¡å‹
    # save_path = 'logs/model/Uet_TV_IMP_7labels_channel3_epoch=40.pth'
    # è®¤ä¸ºconfigä¸€å®šä¸ä¸ºNone

    
    net = UNet(
        in_ch=config['unet_in_channels'],                 # è¾“å…¥é€šé“ï¼š[æœ€å°äºŒä¹˜åˆå§‹è§£, è§‚æµ‹åœ°éœ‡æ•°æ®]
        out_ch=config['unet_out_channels'],                # è¾“å‡ºé€šé“ï¼šé˜»æŠ—æ®‹å·®
        channels=config['unet_channels'],
        skip_channels=config['unet_skip_channels'],
        use_sigmoid=config['unet_use_sigmoid'],        # è¾“å‡ºå½’ä¸€åŒ–åˆ°[0,1]
        use_norm=config['unet_use_norm']
    ).to(device)
    net.load_state_dict(torch.load(model_path2, map_location=device))
    net.eval()

    # æ¨ç†é˜¶æ®µï¼šæ„å»ºå­æ³¢ç®—å­
    # print("ğŸ”§ æ„å»ºæ¨ç†ç”¨å­æ³¢ç®—å­...")
    # å¦‚æœæ²¡æœ‰ä¼ å…¥configï¼Œä½¿ç”¨é»˜è®¤å€¼
    if config is None:
        config = {
            'wavelet_length': 101,
            'epsI': 0.1,
            'gaussian_std': 25
        }
    
    wav0 = wavelet_init(config['wavelet_length']).squeeze().numpy()
    wav00=torch.tensor(wav0[None, None, :, None],device=device)
    # è·å–ç¬¬ä¸€ä¸ªbatchçš„æ•°æ®æ¥ç¡®å®šç»´åº¦
    first_batch = next(iter(test_loader))
    s_patch_first = first_batch[0]
    nz = s_patch_first.shape[2]  # æ—¶é—´ç»´åº¦ï¼Œä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´
    
    # ä½¿ç”¨ä¸è®­ç»ƒæ—¶ç›¸åŒçš„sizeè®¡ç®—æ–¹æ³•
    # è®­ç»ƒæ—¶: size = data_info['seismic_shape'][0]
    # è¿™é‡Œæˆ‘ä»¬éœ€è¦ä»æµ‹è¯•æ•°æ®ä¸­è·å–ç›¸åŒçš„ç»´åº¦
    size = s_patch_first.shape[3]  # patch_sizeï¼Œä¸è®­ç»ƒæ—¶çš„patch_sizeä¸€è‡´
    
    print(f"ğŸ” ç»´åº¦ä¿¡æ¯:")
    print(f"   - s_patch_first.shape: {s_patch_first.shape}")
    print(f"   - shape3d: {shape3d}")
    print(f"   - nz: {nz}")
    print(f"   - size: {size}")
    
    
    # é‡æ–°åˆ›å»ºtest_loaderï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»æ¶ˆè€—äº†ç¬¬ä¸€ä¸ªbatch
    test_loader, xy, shape3d, norm_params = processor.process_test_data(batch_size=500,patch_size=120)
    number_of_patches = len(xy)
    epsI = config['epsI']
    S = torch.diag(0.5 * torch.ones(nz - 1), diagonal=1) - torch.diag(0.5 * torch.ones(nz - 1), diagonal=-1)
    S=S.to(device)
    S[0] = S[-1] = 0

    
    wav_learned_np= forward_net(wav00, wav00)[1].detach().cpu().squeeze().numpy()
    N = len(wav_learned_np)
    std = config['gaussian_std']
    print("N",N)
    print("std",std)
    gaussian_window = gaussian(N, std)
    wav_final = gaussian_window * (wav_learned_np - wav_learned_np.mean())
    wav_final = wav_final / wav_final.max()
    WW = pylops.utils.signalprocessing.convmtx(wav_final, size, len(wav_final) // 2)[:size]
    WW = torch.tensor(WW,device=device)
    WW = WW.float()
    S = S.float()
    WW = WW @ S
    PP = torch.matmul(WW.T, WW) + epsI * torch.eye(WW.shape[0], device=device)
    
    print(f"ğŸ” è°ƒè¯•ä¿¡æ¯:")
    print(f"   - size: {size}")
    print(f"   - WW.shape: {WW.shape}")
    print(f"   - S.shape: {S.shape}")
    print(f"   - PP.shape: {PP.shape}")
    # print(f"âœ… æ¨ç†å­æ³¢ç®—å­æ„å»ºå®Œæˆ:")
    # print(f"   - å­æ³¢é•¿åº¦: {len(wav_final)}")
    # print(f"   - å·ç§¯ç®—å­å½¢çŠ¶: {WW.shape}")
    # print(f"   - å­æ³¢ç±»å‹: {'å­¦ä¹ çš„å­æ³¢' if use_learned_wavelet else 'åˆå§‹å­æ³¢'}")
    # print("ğŸ” å¼€å§‹æµ‹è¯•patchæ¨ç†...")
    # 1. è·å–patch loaderã€ç´¢å¼•ã€shapeã€å½’ä¸€åŒ–å‚æ•°
    
    # 2. æ¨ç†å¾ªç¯
    pred_patch_list = []
    true_patch_list = []
    input_patch_list = []
    back_patch_list = []
    indices_list = []
    seismic_patch_list = []
    logimpmax = norm_params['logimpmax']
    logimpmin = norm_params['logimpmin']
    with torch.no_grad():
        for i, (s_patch, imp_patch, zback_patch,indice ) in enumerate(test_loader):
            s_patch = s_patch.to(device)
            imp_patch = imp_patch.to(device)
            zback_patch = zback_patch.to(device)
            
            if i == 0:  # åªæ‰“å°ç¬¬ä¸€ä¸ªbatchçš„ä¿¡æ¯
                print(f"ğŸ” æ•°æ®å½¢çŠ¶:")
                print(f"   - s_patch.shape: {s_patch.shape}")
                print(f"   - zback_patch.shape: {zback_patch.shape}")
                print(f"   - imp_patch.shape: {imp_patch.shape}")
            
            # æœ€å°äºŒä¹˜åˆå§‹åŒ–
            datarn = torch.matmul(WW.T, s_patch - torch.matmul(WW, zback_patch))
            x, _, _, _ = torch.linalg.lstsq(PP[None, None], datarn)
            Z_init = x + zback_patch
            Z_init = (Z_init - Z_init.min()) / (Z_init.max() - Z_init.min())
            # ç½‘ç»œæ¨ç†
            Z_pred = net(torch.cat([Z_init, s_patch], dim=1)) + Z_init
            # æ”¶é›†patchç»“æœï¼ˆé€‚é…batch>1ï¼‰
            # ç›´æ¥squeezeå’Œtoliståç”¨extendæ‰¹é‡æ·»åŠ ï¼Œé¿å…forå¾ªç¯
            Z_pred_np = np.squeeze(Z_pred.cpu().numpy(), axis=1)  # [batch, time, patch_size]
            imp_patch_np = np.squeeze(imp_patch.cpu().numpy(), axis=1)
            zback_patch_np = np.squeeze(zback_patch.cpu().numpy(), axis=1)
            s_patch_np = np.squeeze(s_patch.cpu().numpy(), axis=1)
            pred_patch_list.extend(list(Z_pred_np))
            true_patch_list.extend(list(imp_patch_np))
            back_patch_list.extend(list(zback_patch_np))
            seismic_patch_list.extend(list(s_patch_np))
            indices_list.extend(indice.tolist())
            current_patches = len(pred_patch_list)
            print(f"   å¤„ç†patch {current_patches}/{number_of_patches}")
    # 3. æ‹¼å›3Dä½“
    # print(f"   æ‹¼å›3Dä½“...") # [N, time, patch_size]
    pred_3d = processor.reconstruct_3d_from_patches(pred_patch_list, indices_list)
    true_3d = processor.reconstruct_3d_from_patches(true_patch_list, indices_list)
    back_3d = processor.reconstruct_3d_from_patches(back_patch_list, indices_list)
    seismic_3d = processor.reconstruct_3d_from_patches(seismic_patch_list, indices_list)
    
    # 4. åå½’ä¸€åŒ–
    # pred_3d_imp = np.exp(pred_3d * (logimpmax - logimpmin) + logimpmin)
    # true_3d_imp = np.exp(true_3d * (logimpmax - logimpmin) + logimpmin)
    # back_3d_imp = np.exp(back_3d * (logimpmax - logimpmin) + logimpmin)
    pred_3d_imp = pred_3d
    true_3d_imp = true_3d
    back_3d_imp = back_3d
    
    # 5. ä¿å­˜æ‰€æœ‰å¯è§†åŒ–éœ€è¦çš„æ–‡ä»¶
    os.makedirs(f'{folder_dir}', exist_ok=True)
    # np.save('logs/results/prediction_sample.npy', np.array(pred_patch_list))
    # np.save('logs/results/true_sample.npy', np.array(true_patch_list))
    # np.save('logs/results/input_sample.npy', np.array(seismic_patch_list))
    # np.save(os.path.join(folder_dir, 'seismic_record.npy'), seismic_3d)
    # np.save(os.path.join(folder_dir, 'prediction_impedance.npy'), pred_3d_imp)
    # np.save(os.path.join(folder_dir, 'true_impedance.npy'), true_3d_imp)
    # np.save(os.path.join(folder_dir, 'background_impedance.npy'), back_3d_imp)

    print(f"âœ… æ¨ç†æ•°æ®å·²ä¿å­˜: {folder_dir}/prediction_impedance.npy ç­‰ shape: {pred_3d_imp.shape}")
    # print("\n" + "="*80)
    # print("ğŸ‰ ç¨‹åºæ‰§è¡Œå®Œæˆ")
    # print("="*80) 
    
    plot_well_curves_seisvis(true_3d_imp, pred_3d_imp, well_pos=None, back_imp=back_3d_imp, save_dir=folder_dir)
    # plot_well_curves_seisvis(true_imp, pred_imp, well_positions, back_imp=back_imp, save_dir='results')
    plot_sections_with_wells(pred_3d_imp, true_3d_imp, back_3d_imp, seismic_3d, well_pos=None, section_type='inline', save_dir=folder_dir)
    plot_sections_with_wells(pred_3d_imp, true_3d_imp, back_3d_imp, seismic_3d, well_pos=None, section_type='xline', save_dir=folder_dir)
    
    # thread1.join()
    # thread2.join()


# model_path1 = '/home/shendi_gjh_cj/codes/3D_project/logs/20250803-17-38-42/model/forward_net_wavelet_learned.pth'  # Forwardå»ºæ¨¡ç½‘ç»œè·¯å¾„
# model_path2='/home/shendi_gjh_cj/codes/3D_project/logs/20250803-17-38-42/model/Uet_TV_IMP_7labels_channel3_epoch=20.pth'
# inference(model_path1,model_path2,folder_dir='logs/test')

# def visualize_thread(pred_3d_imp, true_3d_imp, back_3d_imp, seismic_3d, folder_dir):
#     # å¯è§†åŒ–ç»“æœ
#     plot_sections_with_wells(pred_3d_imp, true_3d_imp, back_3d_imp, seismic_3d, well_pos=None, section_type='inline', save_dir=folder_dir)
#     plot_sections_with_wells(pred_3d_imp, true_3d_imp, back_3d_imp, seismic_3d, well_pos=None, section_type='xline', save_dir=folder_dir)



# inference()