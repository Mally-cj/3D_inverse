## 2024.06.64
## Hongling Chen
## Xi'an Jiaotong University
## multichannel seismic impedance inversion by semi-supervised manner for # ğŸ“š æ¼”ç¤ºç”¨æ•°æ®åŠ è½½ï¼šåœ¨å®é™…å·¥ç¨‹ä¸­ä¸å­˜åœ¨å®Œæ•´çš„çœŸå®é˜»æŠ—
# è¿™é‡Œä¸ºäº†ç®—æ³•éªŒè¯å’Œè®­ç»ƒç›®çš„ï¼Œä½¿ç”¨SEGYæ–‡ä»¶æ¨¡æ‹Ÿ"çœŸå®"é˜»æŠ—
print("ğŸ—„ï¸  Loading reference impedance (for algorithm validation only)...")
print("âš ï¸  æ³¨æ„ï¼šå®é™…å·¥ç¨‹ä¸­ä¸å­˜åœ¨è¿™æ ·çš„å®Œæ•´çœŸå®é˜»æŠ—æ•°æ®")
segy=_read_segy("../data/yyf_smo_train_Volume_PP_IMP.sgy")

impedance_model = np.array([trace.data for trace in segy.traces])
impedance_model = impedance_model.reshape(251, 1189, 601).transpose(2, 1, 0)

# æ ¹æ®è®¾å¤‡é…ç½®è°ƒæ•´æ•°æ®å¤§å°
if not USE_FULL_DATA:
    print(f"ğŸ“Š Reducing data size for CPU: {impedance_model.shape} -> (601, {MAX_SPATIAL_SLICES}, 251)")
    impedance_model = impedance_model[:, :MAX_SPATIAL_SLICES, :]

impedance_model = np.log(impedance_model)
print(f"âœ… Reference impedance loaded: {impedance_model.shape}")
print(f"ğŸ’¾ Memory usage: {get_memory_usage():.1f} MB")cal application
## Test: 

"""
é‡è¦è¯´æ˜ï¼šå®é™…å·¥ç¨‹åº”ç”¨ä¸æ¼”ç¤ºä»£ç çš„åŒºåˆ«
========================================

å®é™…å·¥ç¨‹ä¸­çš„æ•°æ®æƒ…å†µï¼š
1. æµ‹äº•æ•°æ®ï¼šå°‘æ•°å‡ å£äº•ä½ç½®çš„å‡†ç¡®æ³¢é˜»æŠ—æ•°æ®ï¼ˆ1Dï¼Œé«˜æˆæœ¬è·å–ï¼‰
   - äº•ä½åæ ‡å®šä¹‰åœ¨ pos å˜é‡ä¸­ï¼ŒåŒ…å«8å£äº•çš„ä½ç½®
   - è¿™äº›ä½ç½®çš„é˜»æŠ—æ•°æ®æ˜¯é€šè¿‡æµ‹äº•ç›´æ¥è·å¾—çš„ï¼Œå‡†ç¡®åº¦é«˜
2. æ’å€¼é˜»æŠ—ï¼šåˆ©ç”¨æµ‹äº•æ•°æ®é€šè¿‡åœ°è´¨ç»Ÿè®¡å­¦æˆ–å…¶ä»–æ–¹æ³•æ’å€¼å¾—åˆ°çš„å®Œæ•´3Dé˜»æŠ—æ¨¡å‹ï¼ˆä¸å¤Ÿå‡†ç¡®ï¼‰
   - åœ¨äº•ä½å¤„ï¼šå‡†ç¡®ï¼ˆç­‰äºæµ‹äº•æ•°æ®ï¼‰
   - åœ¨äº•é—´ï¼šä¸å‡†ç¡®ï¼ˆé€šè¿‡æ’å€¼ä¼°ç®—ï¼‰
3. ä½é¢‘èƒŒæ™¯ï¼šå¯¹æ’å€¼é˜»æŠ—è¿›è¡Œä½é€šæ»¤æ³¢å¾—åˆ°çš„ä½é¢‘è¶‹åŠ¿
4. åœ°éœ‡æ•°æ®ï¼šé€šè¿‡åœ°éœ‡å‹˜æ¢è·å¾—çš„åå°„æ³¢æ•°æ®

æ•°æ®è·å–çš„ä¸‰æ­¥éª¤æµç¨‹ï¼š
========================================
ç¬¬1æ­¥ï¼šéšæœºè·¯å¾„ç”Ÿæˆä¼ªäºŒç»´å‰–é¢
- ä½¿ç”¨éšæœºè·¯å¾„è¿æ¥8å£äº•ï¼Œç”ŸæˆN_WELL_PROFILESæ¡è¿äº•å‰–é¢
- æ¯ä¸ªå‰–é¢é«˜åº¦å›ºå®šï¼š601ä¸ªæ—¶é—´é‡‡æ ·ç‚¹
- æ¯ä¸ªå‰–é¢é•¿åº¦ä¸å®šï¼šå–å†³äºäº•é—´è¿æ¥è·¯å¾„
- è¾“å‡ºï¼šN_WELL_PROFILESæ¡ä¸å®šé•¿çš„ä¼ªäºŒç»´å‰–é¢

ç¬¬2æ­¥ï¼šæ•°æ®æå–
- æ ¹æ®è¿äº•å‰–é¢åæ ‡ï¼Œä»å®Œæ•´3Dæ•°æ®ä¸­æå–å¯¹åº”çš„2Då‰–é¢æ•°æ®
- æå–å†…å®¹ï¼šä½é¢‘èƒŒæ™¯ã€æ’å€¼é˜»æŠ—ã€çœŸå®é˜»æŠ—ã€åœ°éœ‡æ•°æ®ã€äº•ä½æ©ç 
- ä¿æŒå‰–é¢çš„åŸå§‹å°ºå¯¸ï¼š601Ã—å˜é•¿

ç¬¬3æ­¥ï¼šç»Ÿä¸€è£å‰ª
- å°†ä¸å®šé•¿å‰–é¢è£å‰ªæˆç»Ÿä¸€å¤§å°ï¼š601Ã—PATCH_SIZE
- ä½¿ç”¨æ»‘çª—æ–¹å¼è¿›è¡Œæ•°æ®å¢å¼ºï¼Œé‡å æ­¥é•¿ä¸º5ä¸ªç‚¹
- æœ€ç»ˆç”Ÿæˆç»Ÿä¸€è§„æ ¼çš„è®­ç»ƒæ•°æ®é›†

äº•ä½çº¦æŸæœºåˆ¶ï¼š
- well_pos: å®šä¹‰äº†8å£äº•çš„ç©ºé—´ä½ç½® 
- vWellMask: ç”Ÿæˆäº•ä½æ©ç ï¼Œæ ‡è®°å“ªäº›åŒºåŸŸå—äº•çº¦æŸ
- index*out, index*Cimp1: åœ¨è®­ç»ƒä¸­åªåœ¨äº•ä½å¤„è®¡ç®—ç›‘ç£æŸå¤±
- è¿™æ ·ç¡®ä¿ç½‘ç»œåœ¨äº•ä½å¤„è¾“å‡ºä¸æµ‹äº•æ•°æ®ä¸€è‡´

æœ¬æ¼”ç¤ºä»£ç çš„ç®€åŒ–ï¼š
- ä¸ºäº†è®­ç»ƒå’ŒéªŒè¯ç›®çš„ï¼Œä½¿ç”¨åŒä¸€ä¸ªSEGYæ–‡ä»¶æ¨¡æ‹Ÿä¸åŒç±»å‹çš„æ•°æ®
- impedance_modelï¼šä½œä¸ºè®­ç»ƒç›®æ ‡ï¼ˆåœ¨å®é™…ä¸­ä¸å­˜åœ¨å®Œæ•´çš„çœŸå®é˜»æŠ—ï¼‰
- impedance_model_logï¼šæ¨¡æ‹Ÿæµ‹äº•æ’å€¼ç»“æœï¼ˆå®é™…ä¸­æ¥è‡ªäº•æ•°æ®æ’å€¼ï¼‰
- mbackï¼šä»æ’å€¼é˜»æŠ—æå–çš„ä½é¢‘èƒŒæ™¯ï¼ˆç¬¦åˆå®é™…å·¥ç¨‹åšæ³•ï¼‰

åœ¨å®é™…éƒ¨ç½²æ—¶éœ€è¦ï¼š
- å°†impedance_model_logæ›¿æ¢ä¸ºçœŸå®çš„æµ‹äº•æ’å€¼æ•°æ®
- ç§»é™¤impedance_modelç›¸å…³çš„è®­ç»ƒç›®æ ‡ä»£ç 
- è°ƒæ•´ä¸ºæ— ç›‘ç£æˆ–å¼±ç›‘ç£å­¦ä¹ ç­–ç•¥
""" 


import os
os.environ["CUDA_VISIBLE_DEVICES"] = "0"
import sys
import torch.optim
from Model.net2D import UNet, forward_model  # unet
from Model.utils import *  # unet
from torch.utils import data
from Model.joint_well import *  # unet
import matplotlib.pyplot as plt
import pylops
from pylops.utils.wavelets import ricker
from scipy.signal import filtfilt
from scipy import signal
import torch.nn.functional as F
from scipy.signal.windows import gaussian
from obspy.io.segy.segy import _read_segy
import pdb
import sys
sys.path.append('..')
import data_tools as tools
from icecream import ic 
sys.path.append('../codes')
from cpp_to_py import generate_well_mask as generate_well_mask2
from cpp_to_py import get_wellline_and_mask as get_wellline_and_mask2
import psutil
import gc
from tqdm import tqdm

# å†…å­˜ç›‘æ§å‡½æ•°
def get_memory_usage():
    """è·å–å½“å‰å†…å­˜ä½¿ç”¨æƒ…å†µï¼ˆMBï¼‰"""
    process = psutil.Process(os.getpid())
    return process.memory_info().rss / 1024 / 1024


Train = True

# æ™ºèƒ½è®¾å¤‡æ£€æµ‹å’Œå‚æ•°é…ç½®
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ğŸš€ Using device: {device}")

# æ ¹æ®è®¾å¤‡è‡ªåŠ¨è°ƒæ•´å‚æ•°
if device.type == 'cuda':
    print("ğŸ“Š GPU mode: Using full dataset")
    dtype = torch.cuda.FloatTensor
    # GPUå‚æ•°é…ç½®
    USE_FULL_DATA = True
    MAX_SPATIAL_SLICES = 251  # å®Œæ•´æ•°æ®
    BATCH_SIZE = 10
    PATCH_SIZE = 70
    N_WELL_PROFILES = 30
    ADMM_ITER = 100
    ADMM_ITER1 = 50
    MAX_TRAIN_SAMPLES = None  # ä¸é™åˆ¶
else:
    print("ğŸ’» CPU mode: Using optimized subset")
    dtype = torch.FloatTensor
    # CPUä¼˜åŒ–å‚æ•°é…ç½®
    USE_FULL_DATA = False
    MAX_SPATIAL_SLICES = 50   # å‡å°‘æ•°æ®é‡
    BATCH_SIZE = 1
    PATCH_SIZE = 48
    N_WELL_PROFILES = 10
    ADMM_ITER = 30
    ADMM_ITER1 = 15
    MAX_TRAIN_SAMPLES = 300

print(f"ğŸ“‹ Configuration:")
print(f"  - Spatial slices: {MAX_SPATIAL_SLICES}")
print(f"  - Batch size: {BATCH_SIZE}")
print(f"  - Patch size: {PATCH_SIZE}")
print(f"  - Training samples: {MAX_TRAIN_SAMPLES if MAX_TRAIN_SAMPLES else 'unlimited'}")
print(f"  - Training iterations: {ADMM_ITER} + {ADMM_ITER1}")

#######################################å­æ³¢ã€é˜»æŠ—ã€ä½é¢‘é˜»æŠ—æ•°æ®ä»¥åŠåœ°éœ‡æ•°æ®çš„ç”Ÿæˆè¿‡ç¨‹############################################
### wavelet  ä¸ºäº†æ–¹ä¾¿ï¼Œè°ƒç”¨äº†pylopsä¸­ç°æˆçš„å­æ³¢å‡½æ•°
dt0 = 0.001
ntwav = 51 #half size
wav, twav, wavc = ricker(np.arange(ntwav)*dt0, 30)

# åœ¨å®é™…å·¥ç¨‹åº”ç”¨ä¸­ï¼Œæˆ‘ä»¬åªæœ‰ä»¥ä¸‹çœŸå®æ•°æ®ï¼š
# 1. æµ‹äº•æ’å€¼å¾—åˆ°çš„é˜»æŠ—æ•°æ®ï¼ˆä¸å®Œæ•´ä½†æ˜¯èµ·ç‚¹ï¼‰
# 2. è§‚æµ‹çš„åœ°éœ‡æ•°æ®
# 3. å‡ å£äº•ä½ç½®çš„å‡†ç¡®æµ‹äº•æ•°æ®
print("ï¿½ï¸  æ³¨æ„ï¼šå®é™…å·¥ç¨‹ä¸­ä¸å­˜åœ¨å®Œæ•´çš„çœŸå®é˜»æŠ—æ•°æ®")
print("ğŸ’¾ Memory usage: {get_memory_usage():.1f} MB")

# å®é™…å·¥ç¨‹ä¸­çš„æµ‹äº•æ’å€¼é˜»æŠ—æ•°æ®ï¼ˆæ¨¡æ‹Ÿé€šè¿‡å°‘æ•°äº•æ’å€¼å¾—åˆ°çš„ä¸å®Œæ•´é˜»æŠ—ï¼‰
# åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™åº”è¯¥æ¥è‡ªæµ‹äº•æ•°æ®çš„æ’å€¼ç»“æœï¼Œè€Œä¸æ˜¯å®Œæ•´çš„çœŸå®æ•°æ®
print("ğŸ”„ Loading well-interpolated impedance model...")
# æ³¨æ„ï¼šåœ¨å®é™…å·¥ç¨‹ä¸­ï¼Œè¿™åº”è¯¥æ˜¯é€šè¿‡æµ‹äº•æ•°æ®æ’å€¼ç”Ÿæˆçš„ï¼Œè¿™é‡Œä¸ºäº†æ¼”ç¤ºä½¿ç”¨åŒä¸€æ•°æ®
# åœ¨å®é™…åº”ç”¨ä¸­åº”è¯¥æ›¿æ¢ä¸º: segy = _read_segy("path_to_well_interpolated_impedance.sgy")
# æ³¨æ„ï¼šåœ¨å®é™…å·¥ç¨‹ä¸­ï¼Œè¿™åº”è¯¥æ˜¯é€šè¿‡æµ‹äº•æ•°æ®æ’å€¼ç”Ÿæˆçš„ï¼Œè¿™é‡Œä¸ºäº†æ¼”ç¤ºä½¿ç”¨åŒä¸€æ•°æ®
# åœ¨å®é™…åº”ç”¨ä¸­åº”è¯¥æ›¿æ¢ä¸º: segy = _read_segy("path_to_well_interpolated_impedance.sgy")
segy=_read_segy("../data/yyf_smo_train_Volume_PP_IMP.sgy")
# segy = _read_segy("/home/shendi_chl/BGP/seismic_Impedance_inversion_2D/datasets/intial_imp_m2_fortrain_7wells1.sgy") #field data
impedance_model_log = []
for i in range(0,len(segy.traces)):
    impedance_model_log.append(segy.traces[i].data)

impedance_model_log = np.array(impedance_model_log).reshape(251,len(impedance_model_log)//251,601).transpose(2,1,0)

# æ ¹æ®è®¾å¤‡é…ç½®è°ƒæ•´æ•°æ®å¤§å°
if not USE_FULL_DATA:
    impedance_model_log = impedance_model_log[:, :MAX_SPATIAL_SLICES, :]

impedance_model_log = np.log(impedance_model_log)
print(f"âœ… Well-interpolated impedance loaded: {impedance_model_log.shape}")

# ä»æµ‹äº•æ’å€¼é˜»æŠ—ä¸­æå–ä½é¢‘èƒŒæ™¯æ¨¡å‹ï¼ˆè¿™æ˜¯å®é™…å·¥ç¨‹ä¸­çš„åšæ³•ï¼‰
print("ğŸŒŠ Generating low-frequency background from well-interpolated impedance...")
mback = []
for i in range(impedance_model_log.shape[2]):
    B, A = signal.butter(2, 0.012, 'low') # 2*cuttoff_fre/fs  ä½é€šæ»¤æ³¢è·å–ä½é¢‘æ•°æ®
    m_loww = signal.filtfilt(B, A, impedance_model_log[...,i].T).T
    nsmooth = 3
    m_low = filtfilt(np.ones(nsmooth)/float(nsmooth), 1, m_loww) #ä½é€šæ»¤æ³¢ååœ¨æ—¶é—´åˆ‡ç‰‡ä¸Šæœ‰é«˜é¢‘å™ªéŸ³ï¼Œå¯ä»¥ç¨å¾®å¹³æ»‘ä¸‹
    nsmooth = 3
    m_low = filtfilt(np.ones(nsmooth)/float(nsmooth), 1, m_low.T).T #ä½é€šæ»¤æ³¢ååœ¨æ—¶é—´åˆ‡ç‰‡ä¸Šæœ‰é«˜é¢‘å™ªéŸ³ï¼Œå¯ä»¥ç¨å¾®å¹³æ»‘ä¸‹
    mback.append(m_low[...,None])
mback =  np.concatenate(mback, axis = 2)

#synthetic data from ref  åœ°éœ‡æ•°æ®çš„åˆæˆ,ä¸ºäº†å·æ‡’ï¼ŒåŒæ ·ç”¨äº†pylopä¸­ç°æˆçš„å‡½æ•°
print("âš¡ Generating synthetic seismic data from well-interpolated impedance...")
dims = impedance_model_log.shape
PPop = pylops.avo.poststack.PoststackLinearModelling(wav, nt0=dims[0], spatdims=dims[1:3])

# å®é™…å·¥ç¨‹ä¸­åº”è¯¥ç›´æ¥ä½¿ç”¨è§‚æµ‹çš„åœ°éœ‡æ•°æ®ï¼Œè¿™é‡Œä»æµ‹äº•æ’å€¼é˜»æŠ—åˆæˆåœ°éœ‡æ•°æ®ä½œä¸ºæ¼”ç¤º
syn1 = PPop*impedance_model_log.flatten()
syn1 =  syn1.reshape(impedance_model_log.shape)  #ä»æµ‹äº•æ’å€¼é˜»æŠ—åˆæˆçš„åœ°éœ‡æ•°æ®ï¼ˆæ¨¡æ‹Ÿè§‚æµ‹æ•°æ®ï¼‰

# ä»æµ‹äº•æ’å€¼é˜»æŠ—åˆæˆçš„åœ°éœ‡æ•°æ®ï¼Œç”¨äºæœ‰ç›‘ç£è®­ç»ƒçº¦æŸ
synlog = PPop*impedance_model_log.flatten()    
synlog =  synlog.reshape(impedance_model_log.shape)
print(f"âœ… Synthetic data generated: {syn1.shape}")

# å®é™…å·¥ç¨‹ä¸­çš„æ•°æ®æµç¨‹åº”è¯¥æ˜¯ï¼š
# è§‚æµ‹åœ°éœ‡æ•°æ® -> é˜»æŠ—åæ¼” -> è·å¾—é«˜åˆ†è¾¨ç‡é˜»æŠ—
# è€Œä¸æ˜¯ï¼šé˜»æŠ—æ¨¡å‹ -> åˆæˆåœ°éœ‡æ•°æ® -> é˜»æŠ—åæ¼”

#å¯ä»¥åœ¨æ•°æ®ä¸­åŠ å…¥ä¸€å®šçš„å™ªéŸ³å¹²æ‰°ï¼Œ
# np.random.seed(42)
# syn1 = syn1 + np.random.normal(0, 2e-2, dims)
# # calculate the SNR
# SNR = 10*np.log10(np.linalg.norm(syn1)**2/(np.linalg.norm(np.random.normal(0, 2e-2, dims))**2)) # about 10dB
# print(SNR)

####################################### äº•ä½æ•°æ®å®šä¹‰ ####################################################################
nx, ny = syn1.shape[1:3]
basex=450
basey=212

# å·²çŸ¥æµ‹äº•ä½ç½®çš„ç»å¯¹åæ ‡ï¼ˆè¿™äº›ä½ç½®çš„æ³¢é˜»æŠ—æ•°æ®æ˜¯å‡†ç¡®çš„ï¼Œæ¥è‡ªå®é™…æµ‹äº•ï¼‰
pos=[[594,295],[572,692],[591,996],[532,1053],[603,1212],[561,842],[504,846],[499,597]]
# è½¬æ¢ä¸ºç›¸å¯¹ç½‘æ ¼åæ ‡
well_pos=[[y-basey,x-basex] for [x,y] in pos ]
# well_pos=[[x-basex,y-basey] for [x,y] in pos ]

# æ³¨é‡Šæ‰çš„å…¶ä»–äº•ä½é…ç½®é€‰é¡¹
# well_pos=[[594-basex,]]
# well_pos = [[594-basex,84], [572-212,69], [81,144], [49,79], [109,144], [109,109], [29,29]]  #å‡è®¾å·²çŸ¥äº•çš„ç©ºé—´ä½ç½®
train_well = well_pos

print(f"ğŸ“ äº•ä½ä¿¡æ¯:")
print(f"  - æµ‹äº•ä½ç½®æ•°é‡: {len(well_pos)}")
print(f"  - äº•ä½åæ ‡ (ç½‘æ ¼): {well_pos}")
print(f"  - è¿™äº›ä½ç½®çš„é˜»æŠ—æ•°æ®æ˜¯å‡†ç¡®çš„ï¼ˆæ¥è‡ªå®é™…æµ‹äº•ï¼‰")
print(f"  - å…¶ä»–ä½ç½®çš„é˜»æŠ—æ•°æ®é€šè¿‡æ’å€¼è·å¾—ï¼ˆä¸å¤Ÿå‡†ç¡®ï¼‰")

# plt.figure()
# plt.imshow(impedance_model[102,...].T,cmap='jet',)
# plt.scatter(np.array(train_well)[:,0],np.array(train_well)[:,1],c='b');
# plt.xlabel('Crossline', fontdict={'size': 12})
# plt.ylabel('Inline', fontdict={'size': 12})
# plt.xlim(1, nx)
# plt.ylim(1, ny)
# plt.show()

# ç”Ÿæˆäº•ä½æ©ç ï¼šæ ‡è®°å“ªäº›ä½ç½®æœ‰å‡†ç¡®çš„æµ‹äº•æ•°æ®
grid_shape = syn1.shape[1:3]
vWellMask = generate_well_mask2(well_pos, grid_shape, well_range=15, sigma=5)
# vCrd, vMask = get_wellline_and_mask2(well_pos, grid_shape, vWellMask)

print(f"ğŸ¯ äº•ä½æ©ç ç”Ÿæˆå®Œæˆ:")
print(f"  - ç½‘æ ¼å½¢çŠ¶: {grid_shape}")
print(f"  - äº•ä½å½±å“èŒƒå›´: 15ä¸ªç½‘æ ¼ç‚¹")
print(f"  - æ©ç å½¢çŠ¶: {vWellMask.shape}")
print(f"  - æ©ç ç”¨äºæ ‡è¯†å“ªäº›ä½ç½®æœ‰å‡†ç¡®çš„æµ‹äº•çº¦æŸ")


###################################### æ•°æ®è·å–æµç¨‹ï¼šä¸‰æ­¥éª¤ç”Ÿæˆè®­ç»ƒæ•°æ®é›† ####################################
"""
æ•°æ®è·å–çš„ä¸‰ä¸ªæ­¥éª¤ï¼š
1. éšæœºè·¯å¾„ç”Ÿæˆï¼šä½¿ç”¨éšæœºè·¯å¾„è·å–æ„æˆä¼ªäºŒç»´å‰–é¢çš„äº•å£åæ ‡ï¼Œæ¯ä¸ªäºŒç»´å‰–é¢é«˜ä¸º601ï¼Œé•¿ä¸å®š
2. æ•°æ®æå–ï¼šåˆ©ç”¨è·å¾—çš„äº•å£åæ ‡è·å¾—ç­‰å¤§å°çš„ä½é¢‘ã€æ’å€¼é˜»æŠ—ã€åœ°éœ‡æ•°æ®é›†
3. ç»Ÿä¸€è£å‰ªï¼šå†æ¬¡è£å‰ªæˆ601Ã—70å¤§å°ï¼Œä½¿å¾—æ•°æ®é›†ç»Ÿä¸€å¤§å°
"""

# æ­¥éª¤1: éšæœºè·¯å¾„ç”Ÿæˆè¿äº•å‰–é¢
print(f"ğŸ”— æ­¥éª¤1: ç”Ÿæˆ{N_WELL_PROFILES}æ¡éšæœºè¿äº•å‰–é¢...")
print(f"  - åŸºäº{len(well_pos)}å£äº•çš„ä½ç½®ç”Ÿæˆéšæœºè¿æ¥è·¯å¾„")
print(f"  - æ¯æ¡å‰–é¢å‚ç›´é«˜åº¦: 601ä¸ªé‡‡æ ·ç‚¹")
print(f"  - æ°´å¹³é•¿åº¦: ä¸å®šï¼ˆæ ¹æ®äº•é—´è·¯å¾„å†³å®šï¼‰")

train_well1 = add_labels(train_well)
extension_length = 10  # å»¶é•¿éƒ¨åˆ†çš„é•¿åº¦

# å­˜å‚¨å„ç±»æ•°æ®çš„åˆ—è¡¨
implow_train = []    # ä½é¢‘èƒŒæ™¯æ¨¡å‹æ•°æ®
implog_train = []    # æµ‹äº•æ’å€¼é˜»æŠ—æ•°æ®
syn_train = []       # åˆæˆåœ°éœ‡æ•°æ®
synlog_train = []    # ä»æ’å€¼é˜»æŠ—åˆæˆçš„åœ°éœ‡æ•°æ®
Masks = []           # äº•ä½æ©ç 
path_tem=[]

for i in range(N_WELL_PROFILES):
    # ç”Ÿæˆç¬¬iæ¡éšæœºè¿äº•å‰–é¢çš„åæ ‡ç‚¹
    interpolated_points, vMask = get_wellline_and_mask2(well_pos, grid_shape, vWellMask)
    
    print(f"  å‰–é¢{i+1}: åŒ…å«{len(interpolated_points)}ä¸ªç©ºé—´ç‚¹")
    
    # æ‰©å±•æ©ç åˆ°å®Œæ•´çš„æ—¶é—´-ç©ºé—´ç»´åº¦ (601Ã—ç©ºé—´ç‚¹æ•°)
    vMask = np.tile(vMask, (601,1))
    Masks.append(vMask)
    
    # æ­¥éª¤2: æ ¹æ®è¿äº•å‰–é¢åæ ‡æå–å¯¹åº”çš„æ•°æ®
    # æå–ä½é¢‘èƒŒæ™¯æ¨¡å‹æ²¿ç€è¿äº•å‰–é¢çš„æ•°æ® (601Ã—å‰–é¢é•¿åº¦)
    implow_train.append(mback[:,interpolated_points[:,0], interpolated_points[:,1]])
    
    # æå–åˆæˆåœ°éœ‡æ•°æ®æ²¿ç€è¿äº•å‰–é¢çš„æ•°æ®ï¼ˆå®é™…ä¸­åº”ä¸ºè§‚æµ‹åœ°éœ‡æ•°æ®ï¼‰
    syn_train.append(syn1[:,interpolated_points[:,0], interpolated_points[:,1]])
    
    # æå–ä»æ’å€¼é˜»æŠ—åˆæˆçš„åœ°éœ‡æ•°æ®ï¼ˆç”¨äºæœ‰ç›‘ç£çº¦æŸï¼‰
    synlog_train.append(synlog[:,interpolated_points[:,0], interpolated_points[:,1]])
    
    # æå–æµ‹äº•æ’å€¼é˜»æŠ—æ²¿ç€è¿äº•å‰–é¢çš„æ•°æ®ï¼ˆå®é™…å·¥ç¨‹çš„èµ·ç‚¹æ•°æ®ï¼‰
    implog_train.append(impedance_model_log[:,interpolated_points[:,0], interpolated_points[:,1]])

print(f"âœ… æ­¥éª¤1&2å®Œæˆ: ç”Ÿæˆäº†{N_WELL_PROFILES}æ¡ä¼ªäºŒç»´å‰–é¢ï¼Œæ¯æ¡é«˜åº¦601ç‚¹")
print(f"  - æ¯æ¡å‰–é¢åŒ…å«: ä½é¢‘èƒŒæ™¯ã€æ’å€¼é˜»æŠ—ã€åœ°éœ‡æ•°æ®ã€äº•ä½æ©ç ")
print(f"  - âš ï¸  çœŸå®é˜»æŠ—ä»…ç”¨äºæ€§èƒ½è¯„ä¼°ï¼Œä¸å‚ä¸è®­ç»ƒæŸå¤±è®¡ç®—ï¼")

# æ­¥éª¤3: æ•°æ®å¢å¼º - å°†ä¸å®šé•¿çš„è¿äº•å‰–é¢è£å‰ªæˆç»Ÿä¸€å¤§å°çš„è®­ç»ƒå—
print(f"ğŸ“¦ æ­¥éª¤3: æ•°æ®å¢å¼º - è£å‰ªæˆç»Ÿä¸€å¤§å° {PATCH_SIZE}Ã—{PATCH_SIZE}...")
print(f"  - è¾“å…¥: {N_WELL_PROFILES}æ¡ä¸å®šé•¿è¿äº•å‰–é¢ (601Ã—å˜é•¿)")
print(f"  - è¾“å‡º: ç»Ÿä¸€å¤§å°çš„è®­ç»ƒå— (601Ã—{PATCH_SIZE})")

patchsize = PATCH_SIZE
oversize = 5
print(f"  - é‡å æ­¥é•¿: {oversize}ä¸ªç‚¹ï¼Œç”¨äºæ•°æ®å¢å¼º")

# å­˜å‚¨è£å‰ªåçš„è®­ç»ƒæ•°æ®
implow_train_set = []     # ä½é¢‘èƒŒæ™¯è®­ç»ƒå—
implog_train_set = []     # æµ‹äº•æ’å€¼é˜»æŠ—è®­ç»ƒå—
syn_train_set = []        # åœ°éœ‡æ•°æ®è®­ç»ƒå—
synlog_train_set = []     # æ’å€¼é˜»æŠ—åˆæˆåœ°éœ‡è®­ç»ƒå—
Masks_set = []            # äº•ä½æ©ç è®­ç»ƒå—

for i in range(N_WELL_PROFILES):
    # ä½¿ç”¨image2colså‡½æ•°å°†æ¯æ¡è¿äº•å‰–é¢åˆ‡åˆ†æˆå¤šä¸ª(601, patchsize)çš„å°å—
    # (syn1.shape[0], patchsize) = (601, PATCH_SIZE) æŒ‡å®šåˆ‡åˆ†å—çš„å¤§å°
    # (1, oversize) = (1, 5) æŒ‡å®šé‡å æ­¥é•¿
    
    implow_train_set.append(torch.tensor(image2cols(implow_train[i],(syn1.shape[0],patchsize),(1,oversize))))
    syn_train_set.append(torch.tensor(image2cols(syn_train[i],(syn1.shape[0],patchsize),(1,oversize))))
    synlog_train_set.append(torch.tensor(image2cols(synlog_train[i],(syn1.shape[0],patchsize),(1,oversize))))
    Masks_set.append(torch.tensor(image2cols(Masks[i],(syn1.shape[0],patchsize),(1,oversize))))
    implog_train_set.append(torch.tensor(image2cols(implog_train[i],(syn1.shape[0],patchsize),(1,oversize))))

# å°†æ‰€æœ‰è®­ç»ƒå—æ‹¼æ¥æˆæœ€ç»ˆçš„è®­ç»ƒæ•°æ®é›†
# [batch, channel, height, width] = [N_samples, 1, 601, PATCH_SIZE]
implow_train_set = torch.cat(implow_train_set,0)[...,None].permute(0,3,1,2).type(dtype)
implog_train_set = torch.cat(implog_train_set,0)[...,None].permute(0,3,1,2).type(dtype)
syn_train_set = torch.cat(syn_train_set,0)[...,None].permute(0,3,1,2).type(dtype)
synlog_train_set = torch.cat(synlog_train_set,0)[...,None].permute(0,3,1,2).type(dtype)
Masks_set = torch.cat(Masks_set,0)[...,None].permute(0,3,1,2).type(dtype)

print(f"âœ… æ­¥éª¤3å®Œæˆ: ç”Ÿæˆç»Ÿä¸€è®­ç»ƒæ•°æ®é›†")
print(f"  - æœ€ç»ˆè®­ç»ƒæ ·æœ¬æ•°: {len(syn_train_set)}")
print(f"  - æ¯ä¸ªæ ·æœ¬å¤§å°: {syn_train_set.shape[2]}Ã—{syn_train_set.shape[3]} (æ—¶é—´Ã—ç©ºé—´)")
print(f"  - æ•°æ®ç±»å‹: ä½é¢‘èƒŒæ™¯ã€æ’å€¼é˜»æŠ—ã€åœ°éœ‡æ•°æ®ã€äº•ä½æ©ç ")

#ä¸‹é¢æ˜¯å¯¹è®­ç»ƒæ•°æ®é›†è¿›è¡Œå½’ä¸€åŒ–
logimpmax = impedance_model_log.max()
logimpmin = impedance_model_log.min()
logimp_set1 = (implog_train_set - logimpmin)/(logimpmax - logimpmin)
syn1_set = 2*(syn_train_set - syn_train_set.min())/(syn_train_set.max() - syn_train_set.min())-1
synlog_set = 2*(synlog_train_set - synlog_train_set.min())/(synlog_train_set.max() - synlog_train_set.min())-1
mback_set = (implow_train_set  - logimpmin)/(logimpmax - logimpmin)

# åº”ç”¨è®­ç»ƒæ ·æœ¬é™åˆ¶ï¼ˆä»…é™CPUæ¨¡å¼ï¼‰
if MAX_TRAIN_SAMPLES is not None:
    print(f"ğŸ”„ Limiting training samples to {MAX_TRAIN_SAMPLES} for CPU optimization...")
    total_samples = len(syn1_set)
    if total_samples > MAX_TRAIN_SAMPLES:
        # éšæœºé€‰æ‹©æ ·æœ¬
        indices = torch.randperm(total_samples)[:MAX_TRAIN_SAMPLES]
        syn1_set = syn1_set[indices]
        logimp_set1 = logimp_set1[indices]
        mback_set = mback_set[indices]
        Masks_set = Masks_set[indices]
        synlog_set = synlog_set[indices]
        print(f"ğŸ“Š Reduced training samples from {total_samples} to {len(syn1_set)}")

#ä¸‹é¢æ˜¯å¯¹æµ‹è¯•æ•°æ®é›†çš„å½’ä¸€åŒ–
print("ğŸ”§ Normalizing test data...")
syn1_nor =  2*(syn1 -syn1.min())/(syn1.max()-syn1.min())-1
implow_nor = (mback - logimpmin)/(logimpmax - logimpmin)
implog_nor =  (impedance_model_log-logimpmin)/(logimpmax - logimpmin)

test_data = torch.tensor(syn1_nor[...,None]).permute(2,3,0,1).type(dtype)
test_low = torch.tensor(implow_nor[...,None]).permute(2,3,0,1).type(dtype)
test_implog = torch.tensor(implog_nor[...,None]).permute(2,3,0,1).type(dtype)
test_low = torch.tensor(implow_nor[...,None]).permute(2,3,0,1).type(dtype)
test_imp = torch.tensor(imp_nor[...,None]).permute(2,3,0,1).type(dtype)
test_implog = torch.tensor(implog_nor[...,None]).permute(2,3,0,1).type(dtype)

##è®­ç»ƒæ•°æ®é›†ä¸æµ‹è¯•æ•°æ®é›†çš„ é›†æˆ
print(f"ğŸ“¦ Creating data loaders (batch size: {BATCH_SIZE})...")
batch_size = BATCH_SIZE  # ä½¿ç”¨é…ç½®çš„æ‰¹å¤§å°
Train_loader = data.DataLoader(data.TensorDataset(syn1_set,logimp_set1,logimp_set1,mback_set,Masks_set), batch_size=batch_size, shuffle=True)
Train_loader_sup = data.DataLoader(data.TensorDataset(synlog_set,logimp_set1,mback_set), batch_size=batch_size, shuffle=True)
Test_loader = data.DataLoader(data.TensorDataset(test_data, test_implog, test_implog, test_low), batch_size=batch_size, shuffle=False, drop_last=False)

##ä¸ºäº†ä¿è¯å­æ³¢æ¨¡å—çš„åŠ å¿«æ”¶æ•›åŠ å…¥çš„åˆå§‹å­æ³¢ï¼Œè¿›è€Œç”Ÿæˆå­æ³¢å·ç§¯çŸ©é˜µï¼Œåˆå§‹å­æ³¢å¯ä»¥ä»å¤–é¢è¾“å…¥
wav0 = wavelet_init(syn1_set.cpu().type(torch.float32), 101).squeeze().numpy()
size = syn1.shape[0]
W = pylops.utils.signalprocessing.convmtx(wav0, size, len(wav0) // 2)[:size]
W = torch.tensor(W, dtype=torch.float32, device=device)

##
N = len(wav0)  # çª—çš„é•¿åº¦
fp=30
fs = 1000
std = int((fs/fp)/2)  # æ ‡å‡†å·®ï¼Œå†³å®šçª—çš„å®½åº¦
gaussian_window = gaussian(N, std)
gaus_win = torch.tensor(gaussian_window[None,None,:,None]).type(dtype)

# pdb.set_trace()

#######################################################################################################################
##é˜»æŠ—æ­£æ¼”è¿‡ç¨‹çš„å·®åˆ†ç®—å­
def DIFFZ(z):
    DZ= torch.zeros([z.shape[0], z.shape[1], z.shape[2], z.shape[3]], device=device).type(dtype)
    DZ[...,:-1,:] = 0.5*(z[...,1:, :] - z[..., :-1, :])
    return DZ

#é˜»æŠ—åˆ°åœ°éœ‡æ•°æ®çš„æ­£æ¼”è¿‡ç¨‹ï¼Œpytorchå†™æ³•
class ImpedanceOperator():
    def __init__(self, wav):
        self.wav = wav
    def DIFFZ(self, z): # nonlinear operator
        nz = z.shape[2]
        S= torch.diag(0.5 * torch.ones(nz-1), diagonal=1) - torch.diag(
                    0.5 * torch.ones(nz-1), diagonal=-1)
        S[0] = S[-1] = 0
        DZ = torch.matmul(S.to(device), z)
        return DZ

    def forward(self, z):
        WEIGHT = torch.tensor(self.wav.reshape(1, 1, self.wav.shape[0], 1), device=device).type(dtype)
        For_syn = F.conv2d(self.DIFFZ(z), WEIGHT, stride=1, padding='same')
        return For_syn

def tv_loss(x, alfa): # TVçº¦æŸï¼Œå¯ä»¥åœ¨å™ªéŸ³å¹²æ‰°æƒ…å†µä¸‹æ”¹å–„åæ¼”ç»“æœ
    """
    Isotropic TV loss similar to the one in (cf. [1])
    References
    ----------
    .. [1] https://en.wikipedia.org/wiki/Total_variation_denoising
    """
    dh = torch.abs(x[..., :, 1:] - x[..., :, :-1])
    dw = torch.abs(x[..., 1:, :] - x[..., :-1, :])
    return alfa*torch.mean(2*dh[..., :-1, :] + dw[..., :, :-1]) #ç©ºé—´æ–¹ç¨‹ä¹˜ä»¥2ï¼Œæ˜¯ä¸ºäº†ä½¿ç©ºé—´å¹³æ»‘ï¼Œæ ¹æ®æµ‹è¯•æƒ…å†µï¼Œå¯ä»¥åˆ é™¤

#ç½‘ç»œçš„å®šä¹‰
def get_network_and_input(input_depth=2, n_channels = 1):  # 'meshgrid'
    """ Getting the relevant network and network input (based on the image shape and input depth)
    """
    # net = inverse_model().type(dtype) 
    net = UNet(input_depth, n_channels, channels=(8, 16, 32, 64),  skip_channels=(0, 8, 16, 32),use_sigmoid=True, use_norm=False).to(device)
    return net




#ç½‘ç»œçš„è®­ç»ƒ
def train(net, forward_net, clean_img=True, save_path="", admm_iter=100, admm_iter1=50, LR=0.0005, mu=0.001, yita=10, beta=0 ):

    # get optimizer and loss function:
    mse = torch.nn.MSELoss().type(dtype)  # using MSE loss
    optimizer = torch.optim.Adam(net.parameters(), lr=LR)  # using ADAM opt
    optimizerF = torch.optim.Adam(forward_net.parameters(), lr=LR)
    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=.9, step_size=1000)

    net.train()
    psnr_net_total = []
    total_lossF = []
    epsI = 0.1 #
    for i in range(admm_iter): #å­æ³¢æ¨¡å—çš„è®­ç»ƒéƒ¨åˆ†ï¼Œåˆ©ç”¨æµ‹äº•æ•°æ®çš„åˆæˆæ•°æ®ä¸åœ°éœ‡æ•°æ®çš„åŒ¹é…æŸå¤±å‡½æ•°æ¥è¿›è¡Œç½‘ç»œæ›´æ–°
        print(i)
        for y,Cimp1,Cimp1_dup,impback,index in Train_loader: # Cimp1å¯¹åº”çš„æµ‹äº•æ’å€¼ç”Ÿæˆçš„é˜»æŠ—
            optimizerF.zero_grad()
            lossF =  mse(index * forward_net(DIFFZ(Cimp1), torch.tensor(wav0[None, None, :, None], device=device))[0], index * y)*y.shape[3]
            lossF.backward()
            optimizerF.step()
            total_lossF.append(lossF.detach().cpu().numpy())


    wav00  = forward_net(DIFFZ(Cimp1), torch.tensor(wav0[None, None, :, None], device=device))[1].detach().cpu().squeeze().numpy()
    N = len(wav00)  # çª—çš„é•¿åº¦
    std = 25  # æ ‡å‡†å·®ï¼Œå†³å®šçª—çš„å®½åº¦
    gaussian_window = gaussian(N, std)
    wav00 = gaussian_window*(wav00-wav00.mean()) #å¯¹å­æ³¢è¿›è¡Œä¸€ä¸ªçª—å£å¹³æ»‘ï¼Œå¯ä»¥ä½¿å­æ³¢ä¼°è®¡ç»“æœæ›´ç¨³å¥ï¼Œå› ä¸ºä¸Šè¿°çš„å­æ³¢æ¨¡å—ä¼šå‡ºç°è¾¹ç•Œä¸å¹³æ»‘ï¼Œå¯èƒ½è¿˜å¾—ä»”ç»†è°ƒè°ƒç½‘ç»œå’ŒæŸå¤±å‡½æ•°
    #ç”¨æ–°çš„å­æ³¢ç”Ÿæˆå·ç§¯çŸ©é˜µï¼Œæ„å»ºæ­£æ¼”ç®—å­
    nz = y.shape[2]
    S = torch.diag(0.5 * torch.ones(nz - 1), diagonal=1) - torch.diag(
        0.5 * torch.ones(nz - 1), diagonal=-1)
    S[0] = S[-1] = 0
    WW = pylops.utils.signalprocessing.convmtx(wav00/wav00.max(), size, len(wav00) // 2)[:size]
    WW = torch.tensor(WW, dtype=torch.float32, device=device)
    WW = WW@S.to(device)
    PP = torch.matmul(WW.T, WW) + epsI * torch.eye(WW.shape[0], device=device)
    for i in range(admm_iter1): #unetæ¨¡å—çš„è®­ç»ƒ
        labeled_iter = iter(Train_loader_sup)
        for y, Cimp1, Cimp1_dup, impback, index in Train_loader:
            optimizer.zero_grad()

            datarn = torch.matmul(WW.T, y-torch.matmul(WW, impback))
            x, _, _, _ = torch.linalg.lstsq(PP[None,None],datarn)
            x = x + impback  #æœ€å°äºŒä¹˜è§£
            x = (x-x.min())/(x.max()-x.min())  #è¿›è¡Œäº†ä¸€æ­¥å½’ä¸€åŒ–ï¼Œé¿å…æœ€å°äºŒä¹˜å¤§å°å¸¦æ¥çš„å½±å“
            # x = Cimp1.max()*x/x.max()

            out = net(torch.cat([x, y], dim=1)) + x  #ç½‘ç»œçš„è¾“å‡º
            out_np = out.detach().cpu()

            if beta!=0: # è¿™éƒ¨åˆ†ä»£ç å¯ä»¥åŠ å…¥æœ‰ç›‘ç£å­¦ä¹ éƒ¨åˆ†ï¼Œä½†æ˜¯å¦‚æœæƒ³è¦å……åˆ†åˆ©ç”¨æœ‰ç›‘ç£å­¦ä¹ éƒ¨åˆ†ï¼Œä¸åº”è¯¥åˆ©ç”¨æµ‹äº•æ›²çº¿æ’å€¼ç”Ÿæˆç®€å•çš„æ•°æ®é›†ï¼Œå› ä¸ºå…¶ä¸­æ²¡æœ‰å¼•å…¥é¢å¤–ä¿¡æ¯
                #loading unlabeled data
                try:
                    y_sup, imp_sup, mback_sup = next(labeled_iter)
                except StopIteration:
                    labeled_iter = iter(Train_loader_sup)
                    y_sup, imp_sup, mback_sup = next(labeled_iter)

                datarn = torch.matmul(WW.T, y_sup - torch.matmul(WW, mback_sup))
                x, _, _, _ = torch.linalg.lstsq(PP[None, None], datarn)
                x = x + mback_sup
                x = (x - x.min()) / (x.max() - x.min())

                out_sup = net(torch.cat([x, y_sup], dim=1)) + x
                total_loss_sup = mse(out_sup,imp_sup)
            else:
                total_loss_sup=0

            #åŠç›‘ç£å­¦ä¹ æŸå¤±å‡½æ•°å®šä¹‰
            # index*out: åªåœ¨æµ‹äº•ä½ç½®å¤„è®¡ç®—æŸå¤±ï¼Œindexæ˜¯æ©ç ï¼Œæ ‡è®°å“ªäº›ä½ç½®æœ‰å‡†ç¡®çš„æµ‹äº•æ•°æ®
            # Cimp1: æµ‹äº•æ’å€¼é˜»æŠ—ï¼ˆåœ¨æµ‹äº•ä½ç½®å¤„æ˜¯å‡†ç¡®çš„ï¼‰
            loss_sup = yita*mse(index*out, index*Cimp1)*Cimp1.shape[3]/3  # æµ‹äº•ä½ç½®çº¦æŸæŸå¤±
            loss_unsup = mse(forward_net(DIFFZ(out), torch.tensor(wav0[None, None, :, None], device=device))[0], y)  # åœ°éœ‡æ•°æ®æ‹ŸåˆæŸå¤±

            total_loss = ( loss_unsup +  tv_loss(out, mu) + loss_sup ) + beta*total_loss_sup

            total_loss.backward()
            torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=1)  
            optimizer.step()  
            scheduler.step()
            
            #ä¸€äº›å‚æ•°çš„è¾“å‡ºï¼Œä¸ºäº†ç›‘æµ‹ç½‘ç»œçš„è®­ç»ƒ
            if clean_img is not False:
                  # æ³¨æ„ï¼šå®é™…å·¥ç¨‹ä¸­æ²¡æœ‰å®Œæ•´çš„çœŸå®é˜»æŠ—ç”¨äºæ€§èƒ½è¯„ä¼°
                  # åªèƒ½ç›‘æ§æŸå¤±å‡½æ•°çš„å˜åŒ–
                  print('\r',  '%04d/%04d Loss %f Loss_sup %f Loss_unsup %f total_loss_sup %f' % (i, admm_iter, total_loss.item(), loss_sup, loss_unsup, total_loss_sup), end='')        
            else:
                  print('\r', 'iteration %04d/%04d Loss %f' % (i, admm_iter, total_loss.item()), end='')
            
 
        torch.save(net.state_dict(),save_path+f"_{i:05d}")  #ç½‘ç»œæƒé‡çš„ä¿å­˜
    return wav00, out_np



def test(net, forward_net,save_path="", beta=0.05, mu=0.1):  # LR_x needed only if method!=fixed_point
 
    ##load the net
    net.load_state_dict(torch.load(save_path, map_location=device))
    net.eval()   
    
    # get optimizer and loss function:
    mse = torch.nn.MSELoss().type(dtype)  # using MSE loss
    
    predicted_impedance = []
    true_impedance = []
    true_mback = []
    test_loss = []

    wav00 = forward_net(torch.tensor(wav0[None, None, :, None], device=device), torch.tensor(wav0[None, None, :, None], device=device))[1].detach().cpu().squeeze().numpy()
    N = len(wav00)  # çª—çš„é•¿åº¦
    std = 25  # æ ‡å‡†å·®ï¼Œå†³å®šçª—çš„å®½åº¦
    gaussian_window = gaussian(N, std)
    wav00 = gaussian_window * (wav00 - wav00.mean())
    epsI = 0.1 # depends on the noise level

    nz = size
    S = torch.diag(0.5 * torch.ones(nz - 1), diagonal=1) - torch.diag(
        0.5 * torch.ones(nz - 1), diagonal=-1)
    S[0] = S[-1] = 0
    WW = pylops.utils.signalprocessing.convmtx(wav00/wav00.max(), size, len(wav00) // 2)[:size]
    WW = torch.tensor(WW, dtype=torch.float32, device=device)
    WW = WW@S.to(device)
    PP = torch.matmul(WW.T, WW) + epsI * torch.eye(WW.shape[0], device=device)
    with torch.no_grad():    
        for y,Cimp1,Cimp1_dup,impback in Test_loader:

            datarn = torch.matmul(WW.T, y-torch.matmul(WW, impback))
            x, _, _, _ = torch.linalg.lstsq(PP[None,None],datarn)
            x = x + impback
            x = (x-x.min())/(x.max()-x.min())
            # x = Cimp.max()*x/x.max()

            out = net(torch.cat([x, y], dim=1)) + x
            out_np = out
            
            total_loss = mse(forward_net(DIFFZ(out), torch.tensor(wav0[None, None, :, None], device=device))[0], y)
            test_loss.append(total_loss.item())
            
            # å®é™…å·¥ç¨‹ä¸­åªæœ‰æ’å€¼é˜»æŠ—ï¼Œæ²¡æœ‰çœŸå®é˜»æŠ—
            true_mback.append(impback)
            predicted_impedance.append(out_np)
            
    predicted_impedance = torch.cat(predicted_impedance, dim=0).detach().cpu().numpy()         
    true_mback = torch.cat(true_mback, dim=0).detach().cpu().numpy()
    return true_mback, predicted_impedance, test_loss



## 
print("ğŸš€ Initializing networks...")
net= get_network_and_input()
forward_net = forward_model(nonlinearity="tanh").to(device)
Forward_ope = ImpedanceOperator(wav[::-1].copy())

if Train:
    print(f"ğŸ¯ Starting training with {ADMM_ITER} + {ADMM_ITER1} iterations...")
    INV_wavelet, INV_imp, PSNRT  = train(net, forward_net, 
                                        save_path='Uet_TV_IMP_7labels_channel3.pth',
                                        admm_iter=ADMM_ITER, 
                                        admm_iter1=ADMM_ITER1)
    print("âœ… Training completed!")
else:
    print("ğŸ” Running inference...")
    name=49
    Ture_imp, True_mimp, INV_imp, loss11  = test(net, forward_net, save_path=f'Uet_TV_IMP_7labels_channel3.pth_{name:05d}')
    

    well_pos2 = np.array(well_pos)
    corr = np.corrcoef( INV_imp[:, 0, well_pos2[:, 1], well_pos2[:, 0]].flatten(),  Ture_imp[:, 0, well_pos2[:, 1], well_pos2[:, 0]].flatten())[0,1]
    print(f"Well correlation: {corr:.4f}")
    tools.single_imshow(INV_imp[150,0], vmin=0.2, vmax=1, cmap='jet', title=f'INV_impedance_{name}')
    tools.single_imshow(Ture_imp[150,0], vmin=0.2, vmax=1, cmap='jet', title=f'Ture_imp_{name}')
    tools.single_imshow(True_mimp[150,0], vmin=0.2, vmax=1, cmap='jet', title=f'dipin_{name}')

    # plt.figure();plt.imshow(INV_imp[150,0],vmin=0.2, vmax=1, cmap='jet');
    # plt.xlabel('Trace No.', fontdict={ 'size':12})
    # plt.ylabel('Time (ms)', fontdict={'size':12})
    # plt.show()
    # plt.figure();plt.imshow(Ture_imp[150,0],vmin=0.2, vmax=1, cmap='jet');
    # plt.xlabel('Trace No.', fontdict={ 'size':12})
    # plt.ylabel('Time (ms)', fontdict={'size':12})
    # plt.show()
    # plt.figure();plt.imshow(True_mimp[150,0], vmin=0.2, vmax=1, cmap='jet');
    # plt.xlabel('Trace No.', fontdict={ 'size':12})
    # plt.ylabel('Time (ms)', fontdict={'size':12})
    # plt.show()
    # plt.figure();plt.imshow(syn1, cmap='seismic');plt.show()
    plt.figure()
    plt.plot(INV_imp[0,0,:,31],label=f'inv_imp_{name}')
    plt.plot(Ture_imp[0,0,:,31],label=f'true_imp_{name}')
    plt.plot(True_mimp[0,0,:,31],label=f'dipin_{name}')
    plt.legend()
    plt.show()


    k = 120
    plt.figure();plt.imshow(INV_imp[:,0,k,:],vmin=0.2, vmax=1,cmap='jet', interpolation='bicubic');
    plt.xlabel('Crossline', fontdict={ 'size':12})
    plt.ylabel('Inline', fontdict={'size':12})
    plt.title(f"inv_imp_{name}")
    plt.show()
    plt.figure();plt.imshow(Ture_imp[:,0,k,:],vmin=0.2, vmax=1, cmap='jet');
    plt.xlabel('Crossline', fontdict={ 'size':12})
    plt.ylabel('Inline', fontdict={'size':12})
    plt.title(f"ture_imp_{name}");plt.show()
    plt.figure();plt.imshow(True_mimp[:,0,k,:], vmin=0.2, vmax=1, cmap='jet');
    plt.xlabel('Crossline', fontdict={ 'size':12})
    plt.ylabel('Inline', fontdict={'size':12})
    plt.title(f"dipin_{name}")
    plt.show()

    # plt.figure();plt.imshow(syn1[k,:,:].T, cmap='seismic'); plt.show()
    plt.figure();plt.imshow(implog_nor[k,:,:].T, cmap='jet')
    plt.title(f"true_imp_{name}");
    plt.show()






