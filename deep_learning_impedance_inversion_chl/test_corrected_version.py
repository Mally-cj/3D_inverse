#!/usr/bin/env python3
"""
ä¿®æ­£ç‰ˆä»£ç éªŒè¯è„šæœ¬
================
ç”¨äºŽéªŒè¯ä¿®æ­£ç‰ˆä»£ç çš„æ•°æ®æµå‘å’Œç®—æ³•é€»è¾‘æ­£ç¡®æ€§
"""

import torch
import numpy as np
import sys
import os

def test_data_dimensions():
    """æµ‹è¯•æ•°æ®ç»´åº¦ä¸€è‡´æ€§"""
    print("ðŸ” æµ‹è¯•1ï¼šæ•°æ®ç»´åº¦ä¸€è‡´æ€§")
    
    # æ¨¡æ‹Ÿæ•°æ®ç»´åº¦
    time_samples = 601
    crossline = 50  # CPUæ¨¡å¼ç®€åŒ–
    inline = 251
    batch_size = 2
    patch_size = 48
    
    print(f"   åŽŸå§‹æ•°æ®ç»´åº¦: ({time_samples}, {crossline}, {inline})")
    
    # æ¨¡æ‹Ÿå„ç±»æ•°æ®
    S_obs = torch.randn(batch_size, 1, time_samples, patch_size)      # è§‚æµ‹åœ°éœ‡æ•°æ®
    Z_full = torch.randn(batch_size, 1, time_samples, patch_size)     # å®Œæ•´é˜»æŠ—æ•°æ®
    Z_back = torch.randn(batch_size, 1, time_samples, patch_size)     # ä½Žé¢‘èƒŒæ™¯
    M_mask = torch.rand(batch_size, 1, time_samples, patch_size)      # äº•ä½æŽ©ç  [0,1]
    
    # éªŒè¯ç»´åº¦ä¸€è‡´æ€§
    assert S_obs.shape == Z_full.shape == Z_back.shape == M_mask.shape, "æ•°æ®ç»´åº¦ä¸ä¸€è‡´ï¼"
    print(f"   âœ… æ‰€æœ‰æ•°æ®ç»´åº¦ä¸€è‡´: {S_obs.shape}")
    
    # éªŒè¯æŽ©ç èŒƒå›´
    assert M_mask.min() >= 0 and M_mask.max() <= 1, "äº•ä½æŽ©ç èŒƒå›´é”™è¯¯ï¼"
    print(f"   âœ… äº•ä½æŽ©ç èŒƒå›´æ­£ç¡®: [{M_mask.min():.3f}, {M_mask.max():.3f}]")
    
    return S_obs, Z_full, Z_back, M_mask

def test_loss_functions(S_obs, Z_full, Z_back, M_mask):
    """æµ‹è¯•æŸå¤±å‡½æ•°è®¡ç®—"""
    print("\nðŸ” æµ‹è¯•2ï¼šæŸå¤±å‡½æ•°è®¡ç®—")
    
    # æ¨¡æ‹Ÿé¢„æµ‹ç»“æžœ
    Z_pred = torch.randn_like(Z_full)
    
    # æµ‹è¯•äº•çº¦æŸæŸå¤±ï¼ˆåŠ æƒMSEï¼‰
    mse = torch.nn.MSELoss()
    loss_sup = mse(M_mask * Z_pred, M_mask * Z_full)
    print(f"   âœ… äº•çº¦æŸæŸå¤±è®¡ç®—æ­£å¸¸: {loss_sup.item():.6f}")
    
    # æµ‹è¯•TVæ­£åˆ™åŒ–æŸå¤±
    def tv_loss(x, alfa=1e-4):
        dh = torch.abs(x[..., :, 1:] - x[..., :, :-1])
        dw = torch.abs(x[..., 1:, :] - x[..., :-1, :])
        return alfa * torch.mean(2*dh[..., :-1, :] + dw[..., :, :-1])
    
    loss_tv = tv_loss(Z_pred)
    print(f"   âœ… TVæ­£åˆ™åŒ–æŸå¤±è®¡ç®—æ­£å¸¸: {loss_tv.item():.6f}")
    
    # æµ‹è¯•ç‰©ç†çº¦æŸæŸå¤±ï¼ˆéœ€è¦å·®åˆ†ç®—å­ï¼‰
    def DIFFZ(z):
        DZ = torch.zeros_like(z)
        DZ[..., :-1, :] = 0.5 * (z[..., 1:, :] - z[..., :-1, :])
        return DZ
    
    reflection_coeff = DIFFZ(Z_pred)
    print(f"   âœ… åå°„ç³»æ•°è®¡ç®—æ­£å¸¸: {reflection_coeff.shape}")
    
    return loss_sup, loss_tv, reflection_coeff

def test_data_flow():
    """æµ‹è¯•æ•°æ®æµå‘æ­£ç¡®æ€§"""
    print("\nðŸ” æµ‹è¯•3ï¼šæ•°æ®æµå‘æ­£ç¡®æ€§")
    
    # æ¨¡æ‹ŸUNetè¾“å…¥
    batch_size = 2
    time_samples = 601
    patch_size = 48
    
    Z_init = torch.randn(batch_size, 1, time_samples, patch_size)     # æœ€å°äºŒä¹˜åˆå§‹è§£
    S_obs = torch.randn(batch_size, 1, time_samples, patch_size)      # è§‚æµ‹åœ°éœ‡æ•°æ®
    
    # UNetè¾“å…¥ï¼š[Z_init, S_obs]
    unet_input = torch.cat([Z_init, S_obs], dim=1)  # åº”è¯¥æ˜¯2é€šé“
    assert unet_input.shape[1] == 2, f"UNetè¾“å…¥é€šé“æ•°é”™è¯¯: {unet_input.shape[1]}, åº”è¯¥æ˜¯2"
    print(f"   âœ… UNetè¾“å…¥æ ¼å¼æ­£ç¡®: {unet_input.shape}")
    
    # æ¨¡æ‹ŸUNetè¾“å‡ºï¼ˆæ®‹å·®ï¼‰
    delta_Z = torch.randn(batch_size, 1, time_samples, patch_size)
    Z_pred = delta_Z + Z_init  # æ®‹å·®å­¦ä¹ 
    print(f"   âœ… æ®‹å·®å­¦ä¹ è®¡ç®—æ­£ç¡®: Z_pred = Î”Z + Z_init")
    
    return Z_pred

def test_mask_mechanism():
    """æµ‹è¯•äº•ä½æŽ©ç æœºåˆ¶"""
    print("\nðŸ” æµ‹è¯•4ï¼šäº•ä½æŽ©ç æœºåˆ¶")
    
    # åˆ›å»ºæµ‹è¯•æŽ©ç ï¼šäº•ä½(1.0) + è¿‡æ¸¡åŒº(0.5) + æ’å€¼åŒº(0.0)
    M = torch.zeros(1, 1, 10, 10)
    M[0, 0, 5, 5] = 1.0      # äº•ä½ä¸­å¿ƒ
    M[0, 0, 4:7, 4:7] = 0.5  # äº•å½±å“èŒƒå›´
    # å…¶ä»–ä½ç½®ä¿æŒ0.0
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    Z_pred = torch.ones_like(M) * 0.8  # é¢„æµ‹å€¼
    Z_full = torch.ones_like(M) * 0.6  # å®Œæ•´é˜»æŠ—å€¼
    Z_full[0, 0, 5, 5] = 1.0           # äº•ä½å¤„è®¾ä¸º"çœŸå®ž"å€¼
    
    # è®¡ç®—åŠ æƒæŸå¤±
    mse = torch.nn.MSELoss(reduction='none')
    pointwise_loss = mse(Z_pred, Z_full)
    weighted_loss = M * pointwise_loss
    
    print(f"   âœ… äº•ä½å¤„æŸå¤±æƒé‡: {M[0, 0, 5, 5].item():.1f}")
    print(f"   âœ… è¿‡æ¸¡åŒºæŸå¤±æƒé‡: {M[0, 0, 4, 4].item():.1f}")
    print(f"   âœ… æ’å€¼åŒºæŸå¤±æƒé‡: {M[0, 0, 0, 0].item():.1f}")
    print(f"   âœ… åŠ æƒæŸå¤±æœºåˆ¶éªŒè¯é€šè¿‡")

def test_two_stage_algorithm():
    """æµ‹è¯•ä¸¤é˜¶æ®µç®—æ³•é€»è¾‘"""
    print("\nðŸ” æµ‹è¯•5ï¼šä¸¤é˜¶æ®µç®—æ³•é€»è¾‘")
    
    # é˜¶æ®µ1ï¼šå­æ³¢å­¦ä¹ 
    print("   é˜¶æ®µ1ï¼šå­æ³¢å­¦ä¹ ")
    batch_size = 2
    time_samples = 601  
    patch_size = 48
    wavelet_length = 51
    
    # æ¨¡æ‹Ÿæ•°æ®
    Z_full = torch.randn(batch_size, 1, time_samples, patch_size)
    S_obs = torch.randn(batch_size, 1, time_samples, patch_size)
    M_mask = torch.rand(batch_size, 1, time_samples, patch_size)
    wav_init = torch.randn(1, 1, wavelet_length, 1)
    
    # è®¡ç®—åå°„ç³»æ•°
    def DIFFZ(z):
        DZ = torch.zeros_like(z)
        DZ[..., :-1, :] = 0.5 * (z[..., 1:, :] - z[..., :-1, :])
        return DZ
    
    reflection_coeff = DIFFZ(Z_full)
    print(f"      âœ… åå°„ç³»æ•°è®¡ç®—: {reflection_coeff.shape}")
    
    # æ¨¡æ‹Ÿæ­£æ¼”ï¼ˆç®€åŒ–ï¼‰
    synthetic_seismic = reflection_coeff  # ç®€åŒ–ï¼šå‡è®¾å·ç§¯ä¸æ”¹å˜å°ºå¯¸
    
    # åŠ æƒæŸå¤±
    mse = torch.nn.MSELoss()
    loss_wavelet = mse(M_mask * synthetic_seismic, M_mask * S_obs)
    print(f"      âœ… å­æ³¢å­¦ä¹ æŸå¤±: {loss_wavelet.item():.6f}")
    
    # é˜¶æ®µ2ï¼šé˜»æŠ—åæ¼”
    print("   é˜¶æ®µ2ï¼šé˜»æŠ—åæ¼”")
    Z_back = torch.randn(batch_size, 1, time_samples, patch_size)
    
    # æœ€å°äºŒä¹˜åˆå§‹åŒ–ï¼ˆç®€åŒ–ï¼‰
    Z_init = Z_back + 0.1 * torch.randn_like(Z_back)
    print(f"      âœ… æœ€å°äºŒä¹˜åˆå§‹åŒ–: {Z_init.shape}")
    
    # UNetè¾“å…¥
    unet_input = torch.cat([Z_init, S_obs], dim=1)
    print(f"      âœ… UNetè¾“å…¥å‡†å¤‡: {unet_input.shape}")
    
    # æ¨¡æ‹ŸUNetè¾“å‡º
    delta_Z = 0.1 * torch.randn(batch_size, 1, time_samples, patch_size)
    Z_pred = delta_Z + Z_init
    print(f"      âœ… UNetæ®‹å·®å­¦ä¹ : {Z_pred.shape}")
    
    # ä¸‰é¡¹æŸå¤±
    loss_sup = mse(M_mask * Z_pred, M_mask * Z_full)
    loss_unsup = mse(synthetic_seismic, S_obs)  # ç®€åŒ–
    loss_tv = torch.mean(torch.abs(Z_pred[..., :, 1:] - Z_pred[..., :, :-1]))
    
    print(f"      âœ… äº•çº¦æŸæŸå¤±: {loss_sup.item():.6f}")
    print(f"      âœ… ç‰©ç†çº¦æŸæŸå¤±: {loss_unsup.item():.6f}")
    print(f"      âœ… TVæ­£åˆ™åŒ–æŸå¤±: {loss_tv.item():.6f}")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ðŸ§ª ä¿®æ­£ç‰ˆä»£ç éªŒè¯æµ‹è¯•")
    print("=" * 50)
    
    try:
        # æµ‹è¯•1ï¼šæ•°æ®ç»´åº¦
        S_obs, Z_full, Z_back, M_mask = test_data_dimensions()
        
        # æµ‹è¯•2ï¼šæŸå¤±å‡½æ•°
        loss_sup, loss_tv, reflection_coeff = test_loss_functions(S_obs, Z_full, Z_back, M_mask)
        
        # æµ‹è¯•3ï¼šæ•°æ®æµå‘
        Z_pred = test_data_flow()
        
        # æµ‹è¯•4ï¼šæŽ©ç æœºåˆ¶
        test_mask_mechanism()
        
        # æµ‹è¯•5ï¼šä¸¤é˜¶æ®µç®—æ³•
        test_two_stage_algorithm()
        
        print("\n" + "=" * 50)
        print("ðŸŽ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ä¿®æ­£ç‰ˆä»£ç é€»è¾‘æ­£ç¡®")
        print("=" * 50)
        
        print("\nðŸ“‹ éªŒè¯è¦ç‚¹æ€»ç»“:")
        print("âœ… æ•°æ®ç»´åº¦ç»Ÿä¸€ (S_obs, Z_full, Z_back, M_mask)")
        print("âœ… äº•ä½æŽ©ç æœºåˆ¶ (å·®å¼‚åŒ–ç›‘ç£æƒé‡)")
        print("âœ… ä¸¤é˜¶æ®µç®—æ³•æµç¨‹ (å­æ³¢å­¦ä¹  â†’ é˜»æŠ—åæ¼”)")
        print("âœ… æŸå¤±å‡½æ•°è®¾è®¡ (ç‰©ç†çº¦æŸ + äº•çº¦æŸ + æ­£åˆ™åŒ–)")
        print("âœ… æ®‹å·®å­¦ä¹ æž¶æž„ (Z_pred = UNet([Z_init, S_obs]) + Z_init)")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
