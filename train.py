"""
ç®€åŒ–ç‰ˆåœ°éœ‡é˜»æŠ—åæ¼”ä¸»ç¨‹åº
ä½¿ç”¨ç‹¬ç«‹çš„æ•°æ®å¤„ç†æ¨¡å—å’Œç¼“å­˜æœºåˆ¶
"""

import os
# os.environ["CUDA_VISIBLE_DEVICES"] = "1"  # ä½¿ç”¨ç‰©ç†ç¬¬1å¼ å¡ï¼ˆç¬¬äºŒå¼ å¡ï¼‰
import torch
print(f"å¯è§çš„GPUæ•°é‡: {torch.cuda.device_count()}")
if torch.cuda.is_available():
    print(f"å½“å‰GPUåç§°: {torch.cuda.get_device_name(0)}")
    print(f"å½“å‰GPUç´¢å¼•: {torch.cuda.current_device()}")
else:
    print("CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPU")



import sys
import torch.optim
from Model.net2D import UNet, forward_model
from Model.utils import DIFFZ, tv_loss, wavelet_init, save_stage1_loss_data, save_stage2_loss_data, save_complete_training_loss
import matplotlib.pyplot as plt
import numpy as np
import pylops
from pylops.utils.wavelets import ricker
from scipy.signal import filtfilt
from scipy import signal
import torch.nn.functional as F
from scipy.signal.windows import gaussian
import pdb
import sys
sys.path.append('..')
from icecream import ic 
sys.path.append('../codes')
sys.path.append('deep_learning_impedance_inversion_chl')
import psutil
import gc
from tqdm import tqdm
import json
from pathlib import Path
# å¯¼å…¥æ•°æ®å¤„ç†æ¨¡å—
from data_processor import SeismicDataProcessor
import run_test


PROJECT_DIR = Path(__file__).parent.resolve()
print(f"é¡¹ç›®ç›®å½•: {PROJECT_DIR}")    ##ä½¿ç”¨å¤šçº¿ç¨‹ï¼Œä¸ç”¨ç»å¯¹ç›®å½•ä¼šä¹±





##å¦‚æœä¼ å…¥é…ç½®æ–‡ä»¶ï¼Œåˆ™ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–config
if len(sys.argv) > 1:
    config_file = sys.argv[1]
    with open(config_file, 'r') as f:
        config = json.load(f)
    print(f"ğŸš€ Using config: {config_file}")

    ##å–configçš„åå­—ä¸ºæ–‡ä»¶å¤¹å
    save_dir = os.path.join(PROJECT_DIR,f'logs/'+config_file.split('/')[-1].split('.')[0]+'/')
else:
    ##å¦‚æœæ²¡ä¼ å…¥é…ç½®æ–‡ä»¶ï¼Œåˆ™ä½¿ç”¨é»˜è®¤é…ç½®    
    config={
        'lr1': 1e-4,   ## å­¦ä¹ ç‡
        'lr2': 1e-4,   ## Forwardç½‘ç»œå­¦ä¹ ç‡
        'sup_coeff': 1,   
        'tv_coeff': 1,
        'unsup_coeff':1.0,
        'stage1_epoch_number': 3,
        'stage2_epoch_number': 4,
        'device': 'cuda:0',
        'inference_device': 'cuda:1',
        # æ¨¡å‹ç»“æ„å‚æ•°
        'unet_in_channels': 2,
        'unet_out_channels': 1,
        'unet_channels': [8, 16, 32, 64],
        'unet_skip_channels': [0, 8, 16, 32],
        'unet_use_sigmoid': True,
        'unet_use_norm': False,
        'forward_nonlinearity': "tanh",
        # è®­ç»ƒå‚æ•°
        'scheduler_step_size': 30,
        'scheduler_gamma': 0.9,
        'max_grad_norm': 1.0,
        'wavelet_length': 101,
        'gaussian_std': 25,
        'epsI': 0.1,
        'tv_loss_weight': 1.0,
        'sup_loss_divisor': 3,
        # æ‰“å°å’Œä¿å­˜é—´éš”
        'stage1_print_interval': 20,
        'stage2_print_interval': 10,
        'stage2_loss_save_interval': 5,
        'stage2_complete_loss_save_interval': 5,
        # æ–‡ä»¶è·¯å¾„å’Œå‘½å
        'forward_model_filename': 'forward_net_wavelet_learned.pth',
        'unet_model_prefix': 'Uet_TV_IMP_7labels_channel3',
        'cache_dir': 'cache',
    }
    from datetime import datetime
    save_dir = os.path.join(PROJECT_DIR,f'logs/'+datetime.now().strftime("%Y%m%d-%H-%M-%S")+'/')


device = torch.device(config['device'])
print(f"ğŸš€ Using device: {device}")
dtype = torch.cuda.FloatTensor if device.type == 'cuda' else torch.FloatTensor

model_save_dir= os.path.join(save_dir, 'model')
os.makedirs(model_save_dir, exist_ok=True)
##æŠŠconfigå­˜æˆconfig.jsonåˆ°save_dir
config = {key: value for key, value in config.items() if not isinstance(value, torch.device)}
with open(os.path.join(save_dir, 'config.json'), 'w') as f:
    json.dump(config, f, indent=4, ensure_ascii=False)


#############################################################################################################
### ç¬¬1éƒ¨åˆ†ï¼šæ•°æ®å¤„ç† - ä½¿ç”¨ç‹¬ç«‹çš„æ•°æ®å¤„ç†æ¨¡å—
#############################################################################################################

print("\n" + "="*80) 
print("ğŸ“‚ ç¬¬1éƒ¨åˆ†ï¼šæ•°æ®å¤„ç†")
print("="*80)

# ä¸€é”®å¤„ç†æ‰€æœ‰æ•°æ®
from data_processor import SeismicDataProcessor

processor = SeismicDataProcessor(cache_dir=config['cache_dir'], device=config['device'])

data_info = None  # å…ˆåˆå§‹åŒ–
train_loader, norm_params, data_info = processor.process_train_data()

# æå–å½’ä¸€åŒ–å‚æ•°
logimpmax = norm_params['logimpmax']
logimpmin = norm_params['logimpmin']

print(f"ğŸ“Š æ•°æ®å¤„ç†å®Œæˆ:")
print(f"   - é˜»æŠ—æ•°æ®å½¢çŠ¶: {data_info['impedance_shape']}")
print(f"   - åœ°éœ‡æ•°æ®å½¢çŠ¶: {data_info['seismic_shape']}")
print(f"   - äº•ä½æ•°é‡: {len(data_info['well_positions'])}")



#############################################################################################################
### ç¬¬3éƒ¨åˆ†ï¼šç½‘ç»œåˆå§‹åŒ–
#############################################################################################################

print("\n" + "="*80)
print("ğŸ¤– ç¬¬3éƒ¨åˆ†ï¼šç½‘ç»œåˆå§‹åŒ–")
print("="*80)

# UNeté˜»æŠ—åæ¼”ç½‘ç»œ
print("ğŸ—ï¸  åˆå§‹åŒ–UNetåæ¼”ç½‘ç»œ...")
net = UNet(
    in_ch=config['unet_in_channels'],                 # è¾“å…¥é€šé“ï¼š[æœ€å°äºŒä¹˜åˆå§‹è§£, è§‚æµ‹åœ°éœ‡æ•°æ®]
    out_ch=config['unet_out_channels'],                # è¾“å‡ºé€šé“ï¼šé˜»æŠ—æ®‹å·®
    channels=config['unet_channels'],
    skip_channels=config['unet_skip_channels'],
    use_sigmoid=config['unet_use_sigmoid'],        # è¾“å‡ºå½’ä¸€åŒ–åˆ°[0,1]
    use_norm=config['unet_use_norm']
).to(device)

# Forwardå»ºæ¨¡ç½‘ç»œï¼ˆå­æ³¢å­¦ä¹ ï¼‰
print("âš¡ åˆå§‹åŒ–Forwardå»ºæ¨¡ç½‘ç»œ...")
forward_net = forward_model(nonlinearity=config['forward_nonlinearity']).to(device)

print(f"âœ… ç½‘ç»œåˆå§‹åŒ–å®Œæˆ:")
print(f"   - UNetå‚æ•°é‡: {sum(p.numel() for p in net.parameters()):,}")
print(f"   - Forwardç½‘ç»œå‚æ•°é‡: {sum(p.numel() for p in forward_net.parameters()):,}")
print(f"   - è®¾å¤‡: {device}")

#############################################################################################################
### ç¬¬4éƒ¨åˆ†ï¼šè®­ç»ƒç®—æ³• - ä¸¤é˜¶æ®µè®­ç»ƒ
#############################################################################################################

print("\n" + "="*80)
print("ğŸš€ ç¬¬4éƒ¨åˆ†ï¼šä¸¤é˜¶æ®µè®­ç»ƒç®—æ³•")
print("="*80)


size = data_info['seismic_shape'][0]  # ä»æ•°æ®ä¸­åŠ¨æ€è·å–ï¼Œä¸èƒ½å›ºå®š
##æŒ‰ç…§æ—¶é—´å¹´æœˆæ—¥æ—¶åˆ†ç§’å‘½åæ–‡ä»¶å¤¹


# ä¼˜åŒ–å™¨
optimizerF = torch.optim.Adam(forward_net.parameters(), lr=config['lr1'])   ##å­æ³¢çŸ«æ­£å™¨çš„ä¼˜åŒ–å™¨
optimizer = torch.optim.Adam(net.parameters(), lr=config['lr2'])
scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=config['scheduler_step_size'], gamma=config['scheduler_gamma'])

# æŸå¤±å‡½æ•°
mse = torch.nn.MSELoss()

#########################################################################################################
### é˜¶æ®µ1ï¼šå­æ³¢çŸ«æ­£å™¨ï¼ˆForwardNetï¼‰å­¦ä¹ æœ€ä¼˜å­æ³¢
#########################################################################################################

print("\n" + "-"*60)
print("ğŸŒŠ é˜¶æ®µ1ï¼šå­æ³¢çŸ«æ­£å™¨(ForwardNet)å­¦ä¹ æœ€ä¼˜å­æ³¢")
print("-"*60)
print("ç›®æ ‡ï¼šåˆ©ç”¨äº•ä½é«˜å¯ä¿¡åº¦åŒºåŸŸï¼Œé€šè¿‡ForwardNet(å­æ³¢çŸ«æ­£å™¨)è‡ªé€‚åº”è°ƒæ•´åˆå§‹å­æ³¢ï¼Œä½¿å…¶æ›´è´´åˆå®é™…åœ°éœ‡å“åº”")
print("æŸå¤±ï¼šL_wavelet = ||M âŠ™ [ForwardNet(âˆ‡Z_full, w_0)]_synth - M âŠ™ S_obs||Â²")

psnr_net_total = []
total_lossF = []
epsI = config['epsI']
wav0 = wavelet_init(config['wavelet_length']).squeeze().numpy()
print("å¼€å§‹å­æ³¢çŸ«æ­£å™¨è®­ç»ƒ...")
for i in range(config['stage1_epoch_number']):
    epoch_loss = 0
    batch_count = 0
    
    for S_obs_batch, Z_full_batch, Z_back_batch, M_mask_batch in train_loader:
        optimizerF.zero_grad()
        # è®¡ç®—å®Œæ•´é˜»æŠ—çš„åå°„ç³»æ•°
        reflection_coeff = DIFFZ(Z_full_batch)
        # ForwardNet(å­æ³¢çŸ«æ­£å™¨)ï¼šè¾“å…¥åå°„ç³»æ•°å’Œåˆå§‹å­æ³¢ï¼Œè¾“å‡ºçŸ«æ­£åå­æ³¢å¹¶åˆæˆåœ°éœ‡
        synthetic_seismic, learned_wavelet = forward_net(
            reflection_coeff, 
            torch.tensor(wav0[None, None, :, None], device=device)
        )
        # æŸå¤±ï¼šåˆæˆåœ°éœ‡ä¸è§‚æµ‹åœ°éœ‡çš„æ©ç åŠ æƒMSE
        lossF = mse(
            M_mask_batch * synthetic_seismic, 
            M_mask_batch * S_obs_batch
        ) * S_obs_batch.shape[3]
        lossF.backward()
        optimizerF.step()
        epoch_loss += lossF.item()
        batch_count += 1
    avg_loss = epoch_loss / batch_count
    total_lossF.append(avg_loss)
    if i % config['stage1_print_interval'] == 0:
        print(f"   Epoch {i:04d}/{config['stage1_epoch_number']:04d}, å­æ³¢çŸ«æ­£æŸå¤±: {avg_loss:.6f}")
        print(f"      è¯´æ˜ï¼šæŸå¤±è¶Šå°ï¼ŒForwardNetè¾“å‡ºçš„çŸ«æ­£å­æ³¢åœ¨é«˜å¯ä¿¡åº¦åŒºåŸŸæ‹Ÿåˆè§‚æµ‹æ•°æ®è¶Šå¥½")

# ä¿å­˜é˜¶æ®µ1çš„lossæ•°æ®
save_stage1_loss_data(save_dir, total_lossF)
# æå–çŸ«æ­£åçš„å­æ³¢
print("ğŸ¯ æå–ForwardNetçŸ«æ­£åçš„å­æ³¢...")
with torch.no_grad():
    _, wav_learned = forward_net(
        DIFFZ(Z_full_batch), 
        torch.tensor(wav0[None, None, :, None], device=device)
    )
    wav_learned_np = wav_learned.detach().cpu().squeeze().numpy()
# å­æ³¢åå¤„ç†ï¼ˆé«˜æ–¯çª—å¹³æ»‘ï¼‰
N = len(wav_learned_np) # çª—çš„é•¿åº¦
std = config['gaussian_std']  # æ ‡å‡†å·®ï¼Œå†³å®šçª—çš„å®½åº¦
gaussian_window = gaussian(N, std)
#å¯¹å­æ³¢è¿›è¡Œä¸€ä¸ªçª—å£å¹³æ»‘ï¼Œå¯ä»¥ä½¿å­æ³¢ä¼°è®¡ç»“æœæ›´ç¨³å¥ï¼Œå› ä¸ºä¸Šè¿°çš„å­æ³¢æ¨¡å—ä¼šå‡ºç°è¾¹ç•Œä¸å¹³æ»‘ï¼Œå¯èƒ½è¿˜å¾—ä»”ç»†è°ƒè°ƒç½‘ç»œå’ŒæŸå¤±å‡½æ•°
wav_learned_smooth = gaussian_window * (wav_learned_np - wav_learned_np.mean())
print(f"âœ… é˜¶æ®µ1å®Œæˆï¼šForwardNetçŸ«æ­£å­æ³¢å­¦ä¹ ")
print(f"   - è®­ç»ƒè½®æ¬¡: {config['stage1_epoch_number']}")
print(f"   - æœ€ç»ˆæŸå¤±: {total_lossF[-1]:.6f}")
print(f"   - çŸ«æ­£åå­æ³¢é•¿åº¦: {len(wav_learned_smooth)}")
#########################################################################################################
### é˜¶æ®µ2ï¼šUNeté˜»æŠ—åæ¼”
#########################################################################################################
print("\n" + "-"*60)
print("ğŸ¯ é˜¶æ®µ2ï¼šUNeté˜»æŠ—åæ¼”")
print("-"*60)
print("ç›®æ ‡ï¼šä½¿ç”¨ForwardNetçŸ«æ­£åçš„å­æ³¢è¿›è¡Œé«˜ç²¾åº¦é˜»æŠ—åæ¼”")
print("ç­–ç•¥ï¼šæœ€å°äºŒä¹˜åˆå§‹åŒ– + UNetæ®‹å·®å­¦ä¹ ")
print("æŸå¤±ï¼šL_total = L_unsup + L_sup + L_tv")
# æ„å»ºåŸºäºçŸ«æ­£å­æ³¢çš„å·ç§¯ç®—å­
print("ğŸ”§ æ„å»ºForwardNetçŸ«æ­£åçš„å­æ³¢çš„å·ç§¯ç®—å­...")
nz = S_obs_batch.shape[2]
S = torch.diag(0.5 * torch.ones(nz - 1), diagonal=1) - torch.diag(0.5 * torch.ones(nz - 1), diagonal=-1)
S[0] = S[-1] = 0
WW = pylops.utils.signalprocessing.convmtx(wav_learned_smooth/wav_learned_smooth.max(), size, len(wav_learned_smooth) // 2)[:size]
WW = torch.tensor(WW, dtype=torch.float32, device=device)
WW = WW @ S.to(device)
PP = torch.matmul(WW.T, WW) + epsI * torch.eye(WW.shape[0], device=device) ##æœ€å°äºŒä¹˜è§£çš„ToplitzçŸ©é˜µçš„è£…ç½®
pdb.set_trace()
print(f"âœ… é˜¶æ®µ2å®Œæˆï¼šUNeté˜»æŠ—åæ¼”è®­ç»ƒ")
# ä¿å­˜Forwardç½‘ç»œï¼ˆå­æ³¢çŸ«æ­£å™¨ï¼‰
forward_save_path= os.path.join(model_save_dir, config['forward_model_filename'])
torch.save(forward_net.state_dict(), forward_save_path)

# åˆå§‹åŒ–é˜¶æ®µ2çš„lossè®°å½•åˆ—è¡¨
stage2_total_loss = []
stage2_sup_loss = []
stage2_unsup_loss = []
stage2_tv_loss = []

threads_inference=[]  # ç”¨äºå­˜å‚¨æ¨ç†çº¿ç¨‹

for i in range(config['stage2_epoch_number']):
    epoch_loss = 0
    epoch_loss_sup = 0
    epoch_loss_unsup = 0
    epoch_loss_tv = 0
    batch_count = 0
    for S_obs_batch, Z_full_batch, Z_back_batch, M_mask_batch in train_loader:
        optimizer.zero_grad()
        # æ­¥éª¤1ï¼šæœ€å°äºŒä¹˜åˆå§‹åŒ–
        datarn = torch.matmul(WW.T, S_obs_batch - torch.matmul(WW, Z_back_batch))
        x, _, _, _ = torch.linalg.lstsq(PP[None, None], datarn)
        Z_init = x + Z_back_batch  # åŠ å›ä½é¢‘èƒŒæ™¯
        Z_init = (Z_init - Z_init.min()) / (Z_init.max() - Z_init.min())  # å½’ä¸€åŒ–
        # æ­¥éª¤2ï¼šUNetæ®‹å·®å­¦ä¹ 
        Z_pred = net(torch.cat([Z_init, S_obs_batch], dim=1)) + Z_init
        # ä¸‰é¡¹æŸå¤±å‡½æ•°è®¡ç®—
        # 1. äº•çº¦æŸæŸå¤±ï¼ˆå·®å¼‚åŒ–ç›‘ç£ï¼‰
        loss_sup = config['sup_coeff'] * mse(
            M_mask_batch * Z_pred, 
            M_mask_batch * Z_full_batch
        ) * Z_full_batch.shape[3] / config['sup_loss_divisor']
        # 2. ç‰©ç†çº¦æŸæŸå¤±ï¼ˆæ­£æ¼”ä¸€è‡´æ€§ï¼‰
        pred_reflection = DIFFZ(Z_pred)
        pred_seismic, _ = forward_net(
            pred_reflection, 
            torch.tensor(wav0[None, None, :, None], device=device)  # å§‹ç»ˆç”¨åˆå§‹å­æ³¢åšæ­£æ¼”ä¸€è‡´æ€§
        )
        loss_unsup =  config['unsup_coeff']* mse(pred_seismic, S_obs_batch)
        # 3. æ€»å˜åˆ†æ­£åˆ™åŒ–æŸå¤±ï¼ˆç©ºé—´å¹³æ»‘æ€§ï¼‰
        loss_tv = config['tv_coeff']* tv_loss(Z_pred, config['tv_loss_weight'])
        # æ€»æŸå¤±
        total_loss = loss_unsup + loss_tv + loss_sup
        total_loss.backward()
        torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=config['max_grad_norm'])
        optimizer.step()
        scheduler.step()
        batch_size=S_obs_batch.shape[0]
        epoch_loss += total_loss.item()
        epoch_loss_sup += loss_sup.item()
        epoch_loss_unsup += loss_unsup.item()
        epoch_loss_tv += loss_tv.item()
        batch_count += batch_size
    
    # è®°å½•æ¯ä¸ªepochçš„å¹³å‡æŸå¤±
    avg_total = epoch_loss / batch_count
    avg_sup = epoch_loss_sup / batch_count
    avg_unsup = epoch_loss_unsup / batch_count
    avg_tv = epoch_loss_tv / batch_count
    
    stage2_total_loss.append(avg_total)
    stage2_sup_loss.append(avg_sup)
    stage2_unsup_loss.append(avg_unsup)
    stage2_tv_loss.append(avg_tv)
    
    if i % config['stage2_print_interval'] == 0:
        print(f"   Epoch {i:04d}/{config['stage2_epoch_number']:04d}")
        print(f"      æ€»æŸå¤±: {avg_total:.6f}")
        print(f"      äº•çº¦æŸæŸå¤±: {avg_sup:.6f} (é«˜å¯ä¿¡åº¦åŒºåŸŸåŒ¹é…)")
        print(f"      ç‰©ç†çº¦æŸæŸå¤±: {avg_unsup:.6f} (æ­£æ¼”ä¸€è‡´æ€§)")
        print(f"      TVæ­£åˆ™åŒ–æŸå¤±: {avg_tv:.6f} (ç©ºé—´å¹³æ»‘æ€§)")
        model_save_path = os.path.join(model_save_dir, f'{config["unet_model_prefix"]}_epoch={i}.pth')
        torch.save(net.state_dict(), model_save_path)
        print(f"ğŸ’¾ UNetæ¨¡å‹å·²ä¿å­˜: {model_save_path}")
        test_save_dir= os.path.join(save_dir, 'test', f'test_epoch={i}')
        thread=run_test.inference(model_path1=forward_save_path, model_path2=model_save_path, folder_dir=test_save_dir,inference_device=config['inference_device'], config=config)
        threads_inference.append(thread)
    
    if i % config['stage2_loss_save_interval'] == 0:
        # ä¿å­˜é˜¶æ®µ2çš„lossæ•°æ®
        save_stage2_loss_data(save_dir, stage2_total_loss, stage2_sup_loss, 
                                stage2_unsup_loss, stage2_tv_loss)
    
    # ä¿å­˜å®Œæ•´è®­ç»ƒè¿‡ç¨‹losså¯¹æ¯”å›¾
    if i % config['stage2_complete_loss_save_interval'] == 0:
        save_complete_training_loss(save_dir, total_lossF, stage2_total_loss, 
                                    stage2_sup_loss, stage2_unsup_loss, stage2_tv_loss, 
                                    )


for thread in threads_inference:
    thread.join()  # ç­‰å¾…æ‰€æœ‰æ¨ç†çº¿ç¨‹å®Œæˆ

