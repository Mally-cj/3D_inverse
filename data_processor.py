"""
åœ°éœ‡é˜»æŠ—åæ¼”æ•°æ®å¤„ç†æ¨¡å—
æ”¯æŒæ•°æ®åŠ è½½ã€é¢„å¤„ç†ã€ç¼“å­˜æœºåˆ¶å’Œè®­ç»ƒæ•°æ®æ„å»º
"""

import os
import pickle
import pdb
import hashlib
import numpy as np
import torch
from torch.utils import data
from scipy.signal import filtfilt
from scipy import signal
from obspy.io.segy.segy import _read_segy
from tqdm import tqdm
import sys
sys.path.append('deep_learning_impedance_inversion_chl')
from cpp_to_py import generate_well_mask as generate_well_mask2
from cpp_to_py import get_wellline_and_mask as get_wellline_and_mask2
from Model.utils import image2cols
from Model.joint_well import add_labels
import data_tools as tools

class SeismicDataProcessor:
    """
    åœ°éœ‡æ•°æ®å¤„ç†ç±»
    æ”¯æŒæ•°æ®åŠ è½½ã€é¢„å¤„ç†ã€ç¼“å­˜å’Œè®­ç»ƒæ•°æ®æ„å»º
    """

    def __init__(self, cache_dir='cache', device='auto'):
        """
        åˆå§‹åŒ–æ•°æ®å¤„ç†å™¨

        Args:
            cache_dir: ç¼“å­˜ç›®å½•
            device: è®¾å¤‡ç±»å‹ ('auto', 'cpu', 'cuda')
        """
        self.cache_dir = cache_dir
        os.makedirs(cache_dir, exist_ok=True)

        # è®¾å¤‡é…ç½®
        if device == 'auto':
            self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
        else:
            self.device = torch.device(device)

        # æ ¹æ®è®¾å¤‡è‡ªåŠ¨è°ƒæ•´å‚æ•°
        # if self.device.type == 'cuda':
        self.dtype = torch.cuda.FloatTensor
        self.config = {
            'BATCH_SIZE': 60,
            'PATCH_SIZE': 120,
            'N_WELL_PROFILES': 30
        }
        # else:
        #     self.dtype = torch.FloatTensor
        #     self.config = {
        #         'BATCH_SIZE': 1,
        #         'PATCH_SIZE': 48,
        #         'N_WELL_PROFILES': 10
        #     }

        # æ•°æ®ç¼“å­˜
        self._data_cache = {}
        self._normalization_params = {}

        print(f"ğŸš€ æ•°æ®å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ:")
        print(f"   - è®¾å¤‡: {self.device}")
        print(f"   - ç¼“å­˜ç›®å½•: {cache_dir}")
        print(f"   - é…ç½®: {self.config}")

    def _get_cache_key(self, data_type, **kwargs):
        """ç”Ÿæˆç¼“å­˜é”®"""
        key_parts = [data_type]
        for k, v in sorted(kwargs.items()):
            key_parts.append(f"{k}_{v}")
        key_str = "_".join(key_parts)
        return hashlib.md5(key_str.encode()).hexdigest()

    def _load_from_cache(self, cache_key):
        """ä»ç¼“å­˜åŠ è½½æ•°æ®"""
        cache_file = os.path.join(self.cache_dir, f"{cache_key}.pkl")
        if os.path.exists(cache_file):
            print(f"ğŸ“¦ ä»ç¼“å­˜åŠ è½½: {cache_key}")
            with open(cache_file, 'rb') as f:
                return pickle.load(f)
        return None

    def _save_to_cache(self, cache_key, data):
        """ä¿å­˜æ•°æ®åˆ°ç¼“å­˜"""
        cache_file = os.path.join(self.cache_dir, f"{cache_key}.pkl")
        print(f"ğŸ’¾ ä¿å­˜åˆ°ç¼“å­˜: {cache_key}")
        with open(cache_file, 'wb') as f:
            pickle.dump(data, f)

    def load_impedance_data(self, file_path="data/yyf_smo_train_Volume_PP_IMP.sgy"):
        """
        åŠ è½½é˜»æŠ—æ•°æ®

        Args:
            file_path: é˜»æŠ—æ•°æ®æ–‡ä»¶è·¯å¾„

        Returns:
            impedance_model_full: å®Œæ•´é˜»æŠ—æ•°æ®
        """
        cache_key = self._get_cache_key("impedance",
                                      full_data=True,
                                      max_slices=251)

        # å°è¯•ä»ç¼“å­˜åŠ è½½
        cached_data = self._load_from_cache(cache_key)
        if cached_data is not None:
            return cached_data

        print(f"ğŸ”„ åŠ è½½é˜»æŠ—æ•°æ®: {file_path}")
        segy = _read_segy(file_path)
        impedance_model_full = []

        for i in range(0, len(segy.traces)):
            impedance_model_full.append(segy.traces[i].data)

        impedance_model_full = np.array(impedance_model_full).reshape(
            251, len(impedance_model_full)//251, 601
        ).transpose(2, 1, 0)

        # æ ¹æ®è®¾å¤‡é…ç½®è°ƒæ•´æ•°æ®å¤§å°
        impedance_model_full = impedance_model_full

        impedance_model_full = np.log(impedance_model_full)

        # ä¿å­˜åˆ°ç¼“å­˜
        self._save_to_cache(cache_key, impedance_model_full)

        print(f"âœ… é˜»æŠ—æ•°æ®åŠ è½½å®Œæˆ: {impedance_model_full.shape}")
        return impedance_model_full

    def generate_low_frequency_background(self, impedance_model_full):
        """
        ä»å®Œæ•´é˜»æŠ—æ•°æ®ç”Ÿæˆä½é¢‘èƒŒæ™¯

        Args:
            impedance_model_full: å®Œæ•´é˜»æŠ—æ•°æ®

        Returns:
            Z_back: ä½é¢‘èƒŒæ™¯é˜»æŠ—
        """
        cache_key = self._get_cache_key("low_freq_background",
                                      shape=impedance_model_full.shape)

        # å°è¯•ä»ç¼“å­˜åŠ è½½
        cached_data = self._load_from_cache(cache_key)
        if cached_data is not None:
            return cached_data

        print("ğŸŒŠ ç”Ÿæˆä½é¢‘èƒŒæ™¯é˜»æŠ—...")
        Z_back = []

        for i in range(impedance_model_full.shape[2]):
            B, A = signal.butter(2, 0.012, 'low')  # æˆªæ­¢é¢‘ç‡çº¦12Hz
            m_loww = signal.filtfilt(B, A, impedance_model_full[..., i].T).T
            nsmooth = 3
            m_low = filtfilt(np.ones(nsmooth)/float(nsmooth), 1, m_loww)  # æ—¶é—´æ–¹å‘å¹³æ»‘
            nsmooth = 3
            m_low = filtfilt(np.ones(nsmooth)/float(nsmooth), 1, m_low.T).T  # ç©ºé—´æ–¹å‘å¹³æ»‘
            Z_back.append(m_low[..., None])

        Z_back = np.concatenate(Z_back, axis=2)

        # ä¿å­˜åˆ°ç¼“å­˜
        self._save_to_cache(cache_key, Z_back)

        print(f"âœ… ä½é¢‘èƒŒæ™¯é˜»æŠ—ç”Ÿæˆå®Œæˆ: {Z_back.shape}")
        return Z_back

    def load_seismic_data(self, file_path="data/PSTM_resample1_lf_extension2.sgy"):
        """
        åŠ è½½åœ°éœ‡è§‚æµ‹æ•°æ®

        Args:
            file_path: åœ°éœ‡æ•°æ®æ–‡ä»¶è·¯å¾„

        Returns:
            S_obs: è§‚æµ‹åœ°éœ‡æ•°æ®
        """
        cache_key = self._get_cache_key("seismic",
                                      full_data=True,
                                      max_slices=251)

        # å°è¯•ä»ç¼“å­˜åŠ è½½
        cached_data = self._load_from_cache(cache_key)
        if cached_data is not None:
            return cached_data

        print(f"ğŸŒŠ åŠ è½½åœ°éœ‡è§‚æµ‹æ•°æ®: {file_path}")
        segy_seismic = _read_segy(file_path)
        S_obs = []

        for i in range(0, len(segy_seismic.traces)):
            S_obs.append(segy_seismic.traces[i].data)

        S_obs = np.array(S_obs).reshape(251, len(S_obs)//251, 601).transpose(2, 1, 0)

        # æ ¹æ®è®¾å¤‡é…ç½®è°ƒæ•´æ•°æ®å¤§å°
        S_obs = S_obs

        # ä¿å­˜åˆ°ç¼“å­˜
        self._save_to_cache(cache_key, S_obs)

        print(f"âœ… åœ°éœ‡è§‚æµ‹æ•°æ®åŠ è½½å®Œæˆ: {S_obs.shape}")
        return S_obs

    def generate_well_mask(self, S_obs):
        """
        ç”Ÿæˆäº•ä½æ©ç 

        Args:
            S_obs: è§‚æµ‹åœ°éœ‡æ•°æ®

        Returns:
            well_pos: äº•ä½åæ ‡
            M_well_mask: äº•ä½æ©ç 
            M_well_mask_dict: äº•ä½æ©ç å­—å…¸
        """
        cache_key = self._get_cache_key("well_mask",
                                      shape=S_obs.shape[1:3],
                                      full_data=True)

        # å°è¯•ä»ç¼“å­˜åŠ è½½
        cached_data = self._load_from_cache(cache_key)
        if cached_data is not None:
            return cached_data

        print("ğŸ¯ ç”Ÿæˆäº•ä½æ©ç ...")

        # ç½‘æ ¼å‚æ•°
        nx, ny = S_obs.shape[1:3]
        basex = 450
        basey = 212

        # å®šä¹‰äº•ä½
        pos = [[594,295], [572,692], [591,996], [532,1053],
               [603,1212], [561,842], [504,846], [499,597]]
        well_pos = [[y-basey, x-basex] for [x, y] in pos]

        # ç”Ÿæˆäº•ä½æ©ç 
        grid_shape = S_obs.shape[1:3]
        M_well_mask_dict = generate_well_mask2(well_pos, grid_shape, well_range=15, sigma=5)

        # è½¬æ¢ä¸º2Dæ•°ç»„æ ¼å¼
        M_well_mask = np.zeros(grid_shape)
        for (line, cmp), weight in M_well_mask_dict.items():
            M_well_mask[line, cmp] = weight

        result = (well_pos, M_well_mask, M_well_mask_dict)

        # ä¿å­˜åˆ°ç¼“å­˜
        self._save_to_cache(cache_key, result)

        print(f"âœ… äº•ä½æ©ç ç”Ÿæˆå®Œæˆ:")
        print(f"   - äº•ä½æ•°é‡: {len(well_pos)}")
        print(f"   - æ©ç å½¢çŠ¶: {M_well_mask.shape}")

        return result

    def build_training_profiles(self, Z_back, impedance_model_full, S_obs,
                              well_pos, M_well_mask_dict):
        """
        æ„å»ºè®­ç»ƒå‰–é¢æ•°æ®

        Args:
            Z_back: ä½é¢‘èƒŒæ™¯é˜»æŠ—
            impedance_model_full: å®Œæ•´é˜»æŠ—æ•°æ®
            S_obs: è§‚æµ‹åœ°éœ‡æ•°æ®
            well_pos: äº•ä½åæ ‡
            M_well_mask_dict: äº•ä½æ©ç å­—å…¸

        Returns:
            training_data: è®­ç»ƒæ•°æ®å­—å…¸
        """
        cache_key = self._get_cache_key("training_profiles",
                                      n_profiles=self.config['N_WELL_PROFILES'],
                                      patch_size=self.config['PATCH_SIZE'])

        # å°è¯•ä»ç¼“å­˜åŠ è½½
        cached_data = self._load_from_cache(cache_key)
        if cached_data is not None:
            return cached_data

        print("ğŸ“¦ æ„å»ºè®­ç»ƒå‰–é¢æ•°æ®...")

        # è®­ç»ƒäº•ä½
        train_well = add_labels(well_pos)
        grid_shape = S_obs.shape[1:3]

        # å­˜å‚¨å„ç±»å‰–é¢æ•°æ®
        Z_back_profiles = []
        Z_full_profiles = []
        S_obs_profiles = []
        M_mask_profiles = []
        path_coords = []

        print("   æ­£åœ¨ç”Ÿæˆè¿äº•å‰–é¢...")
        for i in tqdm(range(self.config['N_WELL_PROFILES']), desc="ç”Ÿæˆå‰–é¢"):
            # ç”Ÿæˆéšæœºè¿äº•å‰–é¢
            interpolated_points, vMask = get_wellline_and_mask2(
                well_pos, grid_shape, M_well_mask_dict
            )

            path_coords.append(interpolated_points)

            # æ‰©å±•æ©ç åˆ°æ—¶é—´ç»´åº¦
            vMask_time_extended = np.tile(vMask, (601, 1))
            M_mask_profiles.append(vMask_time_extended)

            # æå–æ²¿å‰–é¢çš„æ•°æ®
            Z_back_profiles.append(Z_back[:, interpolated_points[:, 0], interpolated_points[:, 1]])
            Z_full_profiles.append(impedance_model_full[:, interpolated_points[:, 0], interpolated_points[:, 1]])
            S_obs_profiles.append(S_obs[:, interpolated_points[:, 0], interpolated_points[:, 1]])

        # æ»‘çª—åˆ‡åˆ†ç»Ÿä¸€å°ºå¯¸
        patchsize = self.config['PATCH_SIZE']
        oversize = 5

        Z_back_patches = []
        Z_full_patches = []
        S_obs_patches = []
        M_mask_patches = []

        print("   æ­£åœ¨åˆ‡åˆ†è®­ç»ƒå—...")
        for i in tqdm(range(self.config['N_WELL_PROFILES']), desc="åˆ‡åˆ†æ•°æ®"):
            Z_back_patches.append(torch.tensor(image2cols(
                Z_back_profiles[i], (S_obs.shape[0], patchsize), (1, oversize)
            )))
            Z_full_patches.append(torch.tensor(image2cols(
                Z_full_profiles[i], (S_obs.shape[0], patchsize), (1, oversize)
            )))
            S_obs_patches.append(torch.tensor(image2cols(
                S_obs_profiles[i], (S_obs.shape[0], patchsize), (1, oversize)
            )))
            M_mask_patches.append(torch.tensor(image2cols(
                M_mask_profiles[i], (S_obs.shape[0], patchsize), (1, oversize)
            )))

        # æ‹¼æ¥æ‰€æœ‰è®­ç»ƒå—
        Z_back_train_set = torch.cat(Z_back_patches, 0)[..., None].permute(0, 3, 1, 2).type(self.dtype)
        Z_full_train_set = torch.cat(Z_full_patches, 0)[..., None].permute(0, 3, 1, 2).type(self.dtype)
        S_obs_train_set = torch.cat(S_obs_patches, 0)[..., None].permute(0, 3, 1, 2).type(self.dtype)
        M_mask_train_set = torch.cat(M_mask_patches, 0)[..., None].permute(0, 3, 1, 2).type(self.dtype)

        training_data = {
            'Z_back_train_set': Z_back_train_set,
            'Z_full_train_set': Z_full_train_set,
            'S_obs_train_set': S_obs_train_set,
            'M_mask_train_set': M_mask_train_set
        }

        # ä¿å­˜åˆ°ç¼“å­˜
        self._save_to_cache(cache_key, training_data)

        print(f"âœ… è®­ç»ƒå‰–é¢æ•°æ®æ„å»ºå®Œæˆ:")
        print(f"   - è®­ç»ƒæ ·æœ¬æ€»æ•°: {len(S_obs_train_set)}")
        print(f"   - æ¯ä¸ªæ ·æœ¬å¤§å°: {S_obs_train_set.shape[2]}Ã—{S_obs_train_set.shape[3]}")

        return training_data



    def process_train_data(self):
        """
        åªå¤„ç†è®­ç»ƒæ•°æ®
        Returns:
            train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
            normalization_params: å½’ä¸€åŒ–å‚æ•°
            data_info: æ•°æ®ä¿¡æ¯å­—å…¸
        """
        print("\n" + "="*80)
        print("ğŸš€ å¼€å§‹è®­ç»ƒæ•°æ®å¤„ç†æµç¨‹")
        print("="*80)
        # 1. åŠ è½½é˜»æŠ—æ•°æ®
        impedance_model_full = self.load_impedance_data()
        # 2. ç”Ÿæˆä½é¢‘èƒŒæ™¯
        Z_back = self.generate_low_frequency_background(impedance_model_full)
        # 3. åŠ è½½åœ°éœ‡æ•°æ®
        S_obs = self.load_seismic_data()
        # 4. ç”Ÿæˆäº•ä½æ©ç 
        well_pos, M_well_mask, M_well_mask_dict = self.generate_well_mask(S_obs)
        # 5. æ„å»ºè®­ç»ƒå‰–é¢æ•°æ®
        training_data = self.build_training_profiles(
            Z_back, impedance_model_full, S_obs, well_pos, M_well_mask_dict
        )
        # 6. æ•°æ®å½’ä¸€åŒ–ï¼ˆç›´æ¥å†™åœ¨æ­¤å¤„ï¼‰
        logimpmax = impedance_model_full.max()
        logimpmin = impedance_model_full.min()
        S_obs_min = S_obs.min()
        S_obs_max = S_obs.max()
        Z_full_norm = (training_data['Z_full_train_set'] - logimpmin) / (logimpmax - logimpmin)
        S_obs_norm = 2 * (training_data['S_obs_train_set'] - S_obs_min) / (S_obs_max - S_obs_min) - 1
        Z_back_norm = (training_data['Z_back_train_set'] - logimpmin) / (logimpmax - logimpmin)

        # 7. åˆ›å»ºè®­ç»ƒæ•°æ®åŠ è½½å™¨
        train_loader = data.DataLoader(
            data.TensorDataset(
                S_obs_norm,
                Z_full_norm,
                Z_back_norm,
                training_data['M_mask_train_set']
            ),
            batch_size=self.config['BATCH_SIZE'],
            shuffle=True
        )
        # æ•°æ®ä¿¡æ¯
        data_info = {
            'impedance_shape': impedance_model_full.shape,
            'seismic_shape': S_obs.shape,
            'well_positions': well_pos,
            'config': self.config
        }
        normalization_params = {
            'logimpmax': logimpmax,
            'logimpmin': logimpmin,
            'S_obs_min': S_obs_min,
            'S_obs_max': S_obs_max
        }
        print("\n" + "="*80)
        print("âœ… è®­ç»ƒæ•°æ®å¤„ç†æµç¨‹å®Œæˆ")
        print("="*80)
        return train_loader, normalization_params, data_info



    def build_test_patches_regular(self, S_obs, Z_back, impedance_model_full, patch_size, oversize=70, axis=0):
        """
        æ²¿axisæ–¹å‘æ»‘çª—åˆ‡patchï¼Œå¦ä¸€ä¸ªç©ºé—´è½´å…¨ä¿ç•™ã€‚
        axis=0: xæ–¹å‘æ»‘çª—ï¼ˆinlineï¼‰ï¼Œaxis=1: yæ–¹å‘æ»‘çª—ï¼ˆxlineï¼‰
        è¿”å›: patches, zback_patches, imp_patches, indices, shape3d
        """
        n_time, n_x, n_y = S_obs.shape
        spatial_shape = [n_x, n_y]
        patches, zback_patches, imp_patches, indices = [], [], [], []
        slide_len = spatial_shape[axis]
        keep_len = spatial_shape[1-axis]

        patch_size=min(patch_size,slide_len)
        # ç”Ÿæˆæ»‘çª—ä½ç½®å’Œå¯¹åº”çš„indices
        start_begin=list(range(0, slide_len - patch_size + 1, oversize))
        start_begin+=[slide_len-patch_size]
        
        for start in start_begin:
            end = start + patch_size
            slc = [slice(None)] * 3
            slc[axis+1] = slice(start, end)
            patch = S_obs[tuple(slc)]
            zback_patch = Z_back[tuple(slc)]
            imp_patch = impedance_model_full[tuple(slc)]
            patches.append(torch.tensor(patch, dtype=torch.float32))
            zback_patches.append(torch.tensor(zback_patch, dtype=torch.float32))
            imp_patches.append(torch.tensor(imp_patch, dtype=torch.float32))

            # ä¸ºæ¯ä¸ªpatchè®°å½•å®é™…ä½ç½®
            for j in range(keep_len):
                if axis == 0:
                    indices.append((start, j))  # xæ–¹å‘æ»‘çª—ï¼Œy=j
                else:
                    indices.append((j, start))  # yæ–¹å‘æ»‘çª—ï¼Œx=j

        # å°†patchåˆ—è¡¨å †å æˆå¼ é‡ï¼Œå¹¶ç»Ÿä¸€æˆ [num_patches, 1, time, patch_size] å½¢çŠ¶ï¼Œæ–¹ä¾¿åç»­DataLoaderä½¿ç”¨
        patches = torch.stack(patches).unsqueeze(1)         # [num_patches, 1, time, patch_size]
        zback_patches = torch.stack(zback_patches).unsqueeze(1)
        imp_patches = torch.stack(imp_patches).unsqueeze(1)
        shape3d = (n_time, n_x, n_y)
        return patches, zback_patches, imp_patches, indices, shape3d

    def process_test_data(self, axis=0,batch_size=500,patch_size=70,test_number=None):
        """
        è¿”å›æµ‹è¯•patch loaderã€patchç´¢å¼•ã€shape3dã€å½’ä¸€åŒ–å‚æ•°ï¼Œæ”¯æŒæ–¹å‘é€‰æ‹©
        axis: 0(xæ–¹å‘æ»‘çª—/inline) æˆ– 1(yæ–¹å‘æ»‘çª—/xline)
        """
        self.test_number=test_number
        impedance_model_full = self.load_impedance_data()
        tools.single_imshow(impedance_model_full[0])
        Z_back = self.generate_low_frequency_background(impedance_model_full)
        S_obs = self.load_seismic_data()
        logimpmax = impedance_model_full.max()
        logimpmin = impedance_model_full.min()
        S_obs_norm = 2 * (S_obs - S_obs.min()) / (S_obs.max() - S_obs.min()) - 1
        Z_back_norm = (Z_back - logimpmin) / (logimpmax - logimpmin)
        Z_full_norm = (impedance_model_full - logimpmin) / (logimpmax - logimpmin)
        # patch_size = self.config['PATCH_SIZE']
        self.test_axis=0
        patches, zback_patches, imp_patches, indices, shape3d = self.build_test_patches_regular(
            S_obs_norm, Z_back_norm, Z_full_norm, patch_size, patch_size-10, axis=self.test_axis
        )
        if test_number is None:
            test_number = len(patches)


        indices_tensor = torch.tensor(indices[:test_number], dtype=torch.int)
        test_loader = data.DataLoader(
            data.TensorDataset(patches[:test_number], imp_patches[:test_number], zback_patches[:test_number],indices_tensor[:test_number]),
            batch_size=batch_size, shuffle=False
        )
        normalization_params = {'logimpmax': logimpmax, 'logimpmin': logimpmin}

        return test_loader, indices, shape3d, normalization_params

    def reconstruct_3d_from_patches(self, pred_patches, indices):
        """
        pred_patches: patchåˆ—è¡¨
        indices: [(i, j)]
        """
        
        assert len(pred_patches) == len(indices), "pred_patches å’Œ indices é•¿åº¦ä¸åŒ¹é…"
            
        # è·å–patchå°ºå¯¸
        n_time = pred_patches[0].shape[0]
        patch_size = pred_patches[0].shape[1]
        
        print(f"ğŸ” é‡å»ºä¿¡æ¯:")
        print(f"   - pred_patches æ•°é‡: {len(pred_patches)}")
        print(f"   - indices æ•°é‡: {len(indices)}")
        print(f"   - patch å½¢çŠ¶: {pred_patches[0].shape}")
        print(f"   - test_axis: {self.test_axis}")
        
        # æ ¹æ®indicesæ¨æ–­ç©ºé—´å°ºå¯¸
        if self.test_axis == 0:
            max_i = max(idx[0] for idx in indices) + patch_size
            max_j = max(idx[1] for idx in indices) + 1
        else:
            max_i = max(idx[0] for idx in indices) + 1
            max_j = max(idx[1] for idx in indices) + patch_size
        n_x, n_y = max_i, max_j

        volume = np.zeros((n_time, n_x, n_y))
        count = np.zeros((n_time, n_x, n_y))

        for idx, (i, j) in enumerate(indices):
            patch = pred_patches[idx]  # [time, patch_size]
            if self.test_axis == 0:
                # xæ–¹å‘æ»‘çª—ï¼Œy=j
                volume[:, i:i+patch_size, j] += patch
                count[:, i:i+patch_size, j] += 1
            else:
                # yæ–¹å‘æ»‘çª—ï¼Œx=j
                volume[:, i, j:j+patch_size] += patch
                count[:, i, j:j+patch_size] += 1
        volume /= np.maximum(count, 1)
        return volume

if __name__ == "__main__":
    """æµ‹è¯•æ•°æ®å¤„ç†æ¨¡å—"""
    # åˆ›å»ºæ•°æ®å¤„ç†å™¨
    processor = SeismicDataProcessor(cache_dir='cache')
    # train_loader, normalization_params, data_info = processor.process_train_data()
    test_loader, indices, shape3d, norm_params = processor.process_test_data()


    # å‡è®¾åŸå§‹ 3D æ•°æ®
    S_obs = np.random.rand(601, 1189, 251).astype(np.float32)
    Z_back = np.random.rand(601, 1189, 251).astype(np.float32)
    impedance_model_full = np.random.rand(601, 1189, 251).astype(np.float32)

    # åˆ‡åˆ†
    patches, zback_patches, imp_patches, indices, shape3d = processor.build_test_patches_regular(
        S_obs, Z_back, impedance_model_full, patch_size=500, oversize=70, axis=0
    )
    # pdb.set_trace()
    # æ‹¼æ¥
    reconstructed = processor.reconstruct_3d_from_patches(patches)

    # éªŒè¯
    assert reconstructed.shape == S_obs.shape, f"æ‹¼æ¥åçš„å½¢çŠ¶ {reconstructed.shape} ä¸åŸå§‹å½¢çŠ¶ {S_obs.shape} ä¸ä¸€è‡´"
    print("åˆ‡åˆ†å’Œæ‹¼æ¥é€»è¾‘åŒ¹é…ï¼Œæ•°æ®ä¸€è‡´ï¼")

    # impedance_model_full = processor.load_impedance_data()
    # Z_back = processor.generate_low_frequency_background(impedance_model_full)
    # S_obs = processor.load_seismic_data()
    # logimpmax = impedance_model_full.max()
    # logimpmin = impedance_model_full.min()
    # S_obs_norm = 2 * (S_obs - S_obs.min()) / (S_obs.max() - S_obs.min()) - 1
    # Z_back_norm = (Z_back - logimpmin) / (logimpmax - logimpmin)
    # Z_full_norm = (impedance_model_full - logimpmin) / (logimpmax - logimpmin)
    # patch_size = processor.config['PATCH_SIZE']
    # processor.test_axis=0
    # patches, zback_patches, imp_patches, indices, shape3d = processor.build_test_patches_regular(
    #     S_obs_norm, Z_back_norm, Z_full_norm, patch_size=70, axis=0
    # )
    # %%
    # tools.single_imshow(impedance_model_full[:,:,0])
    # tools.single_imshow(Z_back[:,:,0])
    # tools.single_imshow(S_obs[:,:,0])
    # %%
    ##æ‰“å°æ•°æ®ä¿¡æ¯
    # print(f"\nğŸ“Š æ•°æ®å¤„ç†ç»“æœ:")
    # print(f"   - é˜»æŠ—æ•°æ®å½¢çŠ¶: {data_info['impedance_shape']}")
    # print(f"   - åœ°éœ‡æ•°æ®å½¢çŠ¶: {data_info['seismic_shape']}")
    # print(f"   - äº•ä½æ•°é‡: {len(data_info['well_positions'])}")
    # print(f"   - è®­ç»ƒæ‰¹æ•°: {len(train_loader)}")
    # print(f"   - æµ‹è¯•æ‰¹æ•°: {len(test_loader)}")
    # print(f"   - å½’ä¸€åŒ–å‚æ•°: {norm_params}")