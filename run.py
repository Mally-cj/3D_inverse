"""
ç®€åŒ–ç‰ˆåœ°éœ‡é˜»æŠ—åæ¼”ä¸»ç¨‹åº
ä½¿ç”¨ç‹¬ç«‹çš„æ•°æ®å¤„ç†æ¨¡å—å’Œç¼“å­˜æœºåˆ¶
"""

import os
# os.environ["CUDA_VISIBLE_DEVICES"] = "1"  # ä½¿ç”¨ç‰©ç†ç¬¬1å¼ å¡ï¼ˆç¬¬äºŒå¼ å¡ï¼‰
import torch
print(f"å¯è§çš„GPUæ•°é‡: {torch.cuda.device_count()}")
print(f"å½“å‰GPUåç§°: {torch.cuda.get_device_name(0)}")
print(f"å½“å‰GPUç´¢å¼•: {torch.cuda.current_device()}")



import sys
import torch.optim
from Model.net2D import UNet, forward_model
from Model.utils import DIFFZ, tv_loss, wavelet_init, save_stage1_loss_data, save_stage2_loss_data, save_complete_training_loss
import matplotlib.pyplot as plt
import numpy as np
import pylops
from pylops.utils.wavelets import ricker
from scipy.signal import filtfilt
from scipy import signal
import torch.nn.functional as F
from scipy.signal.windows import gaussian
import pdb
import sys
sys.path.append('..')
from icecream import ic 
sys.path.append('../codes')
sys.path.append('deep_learning_impedance_inversion_chl')
import psutil
import gc
from tqdm import tqdm

from pathlib import Path

PROJECT_DIR = Path(__file__).parent.resolve()
print(f"é¡¹ç›®ç›®å½•: {PROJECT_DIR}")    ##ä½¿ç”¨å¤šçº¿ç¨‹ï¼Œä¸ç”¨ç»å¯¹ç›®å½•ä¼šä¹±

# å¯¼å…¥æ•°æ®å¤„ç†æ¨¡å—
from data_processor import SeismicDataProcessor
import run_test

# è®­ç»ƒ/æµ‹è¯•æ¨¡å¼åˆ‡æ¢
Train = True  # è®¾ç½®ä¸º True è¿›è¡Œè®­ç»ƒå¹¶ä¿å­˜Forwardç½‘ç»œæƒé‡ï¼›è®¾ç½®ä¸º False è¿›è¡Œæ¨ç†æµ‹è¯•

# ğŸ“ é‡è¦è¯´æ˜ï¼š
# - é¦–æ¬¡ä½¿ç”¨æ—¶ï¼Œå»ºè®®å…ˆè®¾ç½® Train = True è¿è¡Œä¸€æ¬¡è®­ç»ƒï¼Œç”ŸæˆForwardç½‘ç»œæƒé‡æ–‡ä»¶
# - Forwardç½‘ç»œå­¦ä¹ æ•°æ®é©±åŠ¨çš„æœ€ä¼˜å­æ³¢ï¼Œå¯¹åæ¼”ç²¾åº¦è‡³å…³é‡è¦
# - è®­ç»ƒå®Œæˆåï¼Œå¯è®¾ç½® Train = False è¿›è¡Œæ¨ç†æµ‹è¯•

# æ™ºèƒ½è®¾å¤‡æ£€æµ‹å’Œå‚æ•°é…ç½®
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print(f"ğŸš€ Using device: {device}")

# æ ¹æ®è®¾å¤‡è‡ªåŠ¨è°ƒæ•´å‚æ•°
if device.type == 'cuda':
    print("ğŸ“Š GPU mode: Using full dataset")
    dtype = torch.cuda.FloatTensor
else:
    print("ğŸ’» CPU mode: Using optimized subset")
    dtype = torch.FloatTensor

#############################################################################################################
### ç¬¬1éƒ¨åˆ†ï¼šæ•°æ®å¤„ç† - ä½¿ç”¨ç‹¬ç«‹çš„æ•°æ®å¤„ç†æ¨¡å—
#############################################################################################################

print("\n" + "="*80) 
print("ğŸ“‚ ç¬¬1éƒ¨åˆ†ï¼šæ•°æ®å¤„ç†")
print("="*80)

# ä¸€é”®å¤„ç†æ‰€æœ‰æ•°æ®
from data_processor import SeismicDataProcessor

processor = SeismicDataProcessor(cache_dir='cache', device='auto')

data_info = None  # å…ˆåˆå§‹åŒ–
train_loader, norm_params, data_info = processor.process_train_data()

# æå–å½’ä¸€åŒ–å‚æ•°
logimpmax = norm_params['logimpmax']
logimpmin = norm_params['logimpmin']

print(f"ğŸ“Š æ•°æ®å¤„ç†å®Œæˆ:")
print(f"   - é˜»æŠ—æ•°æ®å½¢çŠ¶: {data_info['impedance_shape']}")
print(f"   - åœ°éœ‡æ•°æ®å½¢çŠ¶: {data_info['seismic_shape']}")
print(f"   - äº•ä½æ•°é‡: {len(data_info['well_positions'])}")



#############################################################################################################
### ç¬¬3éƒ¨åˆ†ï¼šç½‘ç»œåˆå§‹åŒ–
#############################################################################################################

print("\n" + "="*80)
print("ğŸ¤– ç¬¬3éƒ¨åˆ†ï¼šç½‘ç»œåˆå§‹åŒ–")
print("="*80)

# UNeté˜»æŠ—åæ¼”ç½‘ç»œ
print("ğŸ—ï¸  åˆå§‹åŒ–UNetåæ¼”ç½‘ç»œ...")
net = UNet(
    in_ch=2,                 # è¾“å…¥é€šé“ï¼š[æœ€å°äºŒä¹˜åˆå§‹è§£, è§‚æµ‹åœ°éœ‡æ•°æ®]
    out_ch=1,                # è¾“å‡ºé€šé“ï¼šé˜»æŠ—æ®‹å·®
    channels=[8, 16, 32, 64],
    skip_channels=[0, 8, 16, 32],
    use_sigmoid=True,        # è¾“å‡ºå½’ä¸€åŒ–åˆ°[0,1]
    use_norm=False
).to(device)

# Forwardå»ºæ¨¡ç½‘ç»œï¼ˆå­æ³¢å­¦ä¹ ï¼‰
print("âš¡ åˆå§‹åŒ–Forwardå»ºæ¨¡ç½‘ç»œ...")
forward_net = forward_model(nonlinearity="tanh").to(device)

print(f"âœ… ç½‘ç»œåˆå§‹åŒ–å®Œæˆ:")
print(f"   - UNetå‚æ•°é‡: {sum(p.numel() for p in net.parameters()):,}")
print(f"   - Forwardç½‘ç»œå‚æ•°é‡: {sum(p.numel() for p in forward_net.parameters()):,}")
print(f"   - è®¾å¤‡: {device}")

#############################################################################################################
### ç¬¬4éƒ¨åˆ†ï¼šè®­ç»ƒç®—æ³• - ä¸¤é˜¶æ®µè®­ç»ƒ
#############################################################################################################

print("\n" + "="*80)
print("ğŸš€ ç¬¬4éƒ¨åˆ†ï¼šä¸¤é˜¶æ®µè®­ç»ƒç®—æ³•")
print("="*80)

# è®­ç»ƒå‚æ•°
lr = 1e-3
size = data_info['seismic_shape'][0]
##æŒ‰ç…§æ—¶é—´å¹´æœˆæ—¥æ—¶åˆ†ç§’å‘½åæ–‡ä»¶å¤¹

config={
    'lr1': 1e-4,   ## å­¦ä¹ ç‡
    'lr2': 1e-4,   ## Forwardç½‘ç»œå­¦ä¹ ç‡
    'sup_coeff': 1,   
    'tv_coeff': 1,
    'unsup_coeff':1.0,
    'stage1_epoch_number': 100,
    'stage2_epoch_number': 40,
    'size': size,
    'device': device
}

from datetime import datetime
save_dir = os.path.join(PROJECT_DIR,f'logs/'+datetime.now().strftime("%Y%m%d-%H-%M-%S")+'/')
model_save_dir= os.path.join(save_dir, 'model')
os.makedirs(model_save_dir, exist_ok=True)
##æŠŠconfigå­˜æˆconfig.jsonåˆ°save_dir
import json
config = {key: value for key, value in config.items() if not isinstance(value, torch.device)}
with open(os.path.join(save_dir, 'config.json'), 'w') as f:
    json.dump(config, f, indent=4, ensure_ascii=False)

# ä¼˜åŒ–å™¨
optimizerF = torch.optim.Adam(forward_net.parameters(), lr=config['lr1'])   ##å­æ³¢çŸ«æ­£å™¨çš„ä¼˜åŒ–å™¨
optimizer = torch.optim.Adam(net.parameters(), lr=config['lr2'])
scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.9)

# æŸå¤±å‡½æ•°
mse = torch.nn.MSELoss()

#########################################################################################################
### é˜¶æ®µ1ï¼šå­æ³¢çŸ«æ­£å™¨ï¼ˆForwardNetï¼‰å­¦ä¹ æœ€ä¼˜å­æ³¢
#########################################################################################################

print("\n" + "-"*60)
print("ğŸŒŠ é˜¶æ®µ1ï¼šå­æ³¢çŸ«æ­£å™¨(ForwardNet)å­¦ä¹ æœ€ä¼˜å­æ³¢")
print("-"*60)
print("ç›®æ ‡ï¼šåˆ©ç”¨äº•ä½é«˜å¯ä¿¡åº¦åŒºåŸŸï¼Œé€šè¿‡ForwardNet(å­æ³¢çŸ«æ­£å™¨)è‡ªé€‚åº”è°ƒæ•´åˆå§‹å­æ³¢ï¼Œä½¿å…¶æ›´è´´åˆå®é™…åœ°éœ‡å“åº”")
print("æŸå¤±ï¼šL_wavelet = ||M âŠ™ [ForwardNet(âˆ‡Z_full, w_0)]_synth - M âŠ™ S_obs||Â²")

psnr_net_total = []
total_lossF = []
epsI = 0.1
wav0 = wavelet_init(101).squeeze().numpy()
print("å¼€å§‹å­æ³¢çŸ«æ­£å™¨è®­ç»ƒ...")
for i in range(config['stage1_epoch_number']):
    epoch_loss = 0
    batch_count = 0
    
    for S_obs_batch, Z_full_batch, Z_back_batch, M_mask_batch in train_loader:
        optimizerF.zero_grad()
        # è®¡ç®—å®Œæ•´é˜»æŠ—çš„åå°„ç³»æ•°
        reflection_coeff = DIFFZ(Z_full_batch)
        # ForwardNet(å­æ³¢çŸ«æ­£å™¨)ï¼šè¾“å…¥åå°„ç³»æ•°å’Œåˆå§‹å­æ³¢ï¼Œè¾“å‡ºçŸ«æ­£åå­æ³¢å¹¶åˆæˆåœ°éœ‡
        synthetic_seismic, learned_wavelet = forward_net(
            reflection_coeff, 
            torch.tensor(wav0[None, None, :, None], device=device)
        )
        # æŸå¤±ï¼šåˆæˆåœ°éœ‡ä¸è§‚æµ‹åœ°éœ‡çš„æ©ç åŠ æƒMSE
        lossF = mse(
            M_mask_batch * synthetic_seismic, 
            M_mask_batch * S_obs_batch
        ) * S_obs_batch.shape[3]
        lossF.backward()
        optimizerF.step()
        epoch_loss += lossF.item()
        batch_count += 1
    avg_loss = epoch_loss / batch_count
    total_lossF.append(avg_loss)
    if i % 20 == 0:
        print(f"   Epoch {i:04d}/{config['stage1_epoch_number']:04d}, å­æ³¢çŸ«æ­£æŸå¤±: {avg_loss:.6f}")
        print(f"      è¯´æ˜ï¼šæŸå¤±è¶Šå°ï¼ŒForwardNetè¾“å‡ºçš„çŸ«æ­£å­æ³¢åœ¨é«˜å¯ä¿¡åº¦åŒºåŸŸæ‹Ÿåˆè§‚æµ‹æ•°æ®è¶Šå¥½")

# ä¿å­˜é˜¶æ®µ1çš„lossæ•°æ®
save_stage1_loss_data(save_dir, total_lossF)
# æå–çŸ«æ­£åçš„å­æ³¢
print("ğŸ¯ æå–ForwardNetçŸ«æ­£åçš„å­æ³¢...")
with torch.no_grad():
    _, wav_learned = forward_net(
        DIFFZ(Z_full_batch), 
        torch.tensor(wav0[None, None, :, None], device=device)
    )
    wav_learned_np = wav_learned.detach().cpu().squeeze().numpy()
# å­æ³¢åå¤„ç†ï¼ˆé«˜æ–¯çª—å¹³æ»‘ï¼‰
N = len(wav_learned_np) # çª—çš„é•¿åº¦
std = 25  # æ ‡å‡†å·®ï¼Œå†³å®šçª—çš„å®½åº¦
gaussian_window = gaussian(N, std)
#å¯¹å­æ³¢è¿›è¡Œä¸€ä¸ªçª—å£å¹³æ»‘ï¼Œå¯ä»¥ä½¿å­æ³¢ä¼°è®¡ç»“æœæ›´ç¨³å¥ï¼Œå› ä¸ºä¸Šè¿°çš„å­æ³¢æ¨¡å—ä¼šå‡ºç°è¾¹ç•Œä¸å¹³æ»‘ï¼Œå¯èƒ½è¿˜å¾—ä»”ç»†è°ƒè°ƒç½‘ç»œå’ŒæŸå¤±å‡½æ•°
wav_learned_smooth = gaussian_window * (wav_learned_np - wav_learned_np.mean())
print(f"âœ… é˜¶æ®µ1å®Œæˆï¼šForwardNetçŸ«æ­£å­æ³¢å­¦ä¹ ")
print(f"   - è®­ç»ƒè½®æ¬¡: {config['stage1_epoch_number']}")
print(f"   - æœ€ç»ˆæŸå¤±: {total_lossF[-1]:.6f}")
print(f"   - çŸ«æ­£åå­æ³¢é•¿åº¦: {len(wav_learned_smooth)}")
#########################################################################################################
### é˜¶æ®µ2ï¼šUNeté˜»æŠ—åæ¼”
#########################################################################################################
print("\n" + "-"*60)
print("ğŸ¯ é˜¶æ®µ2ï¼šUNeté˜»æŠ—åæ¼”")
print("-"*60)
print("ç›®æ ‡ï¼šä½¿ç”¨ForwardNetçŸ«æ­£åçš„å­æ³¢è¿›è¡Œé«˜ç²¾åº¦é˜»æŠ—åæ¼”")
print("ç­–ç•¥ï¼šæœ€å°äºŒä¹˜åˆå§‹åŒ– + UNetæ®‹å·®å­¦ä¹ ")
print("æŸå¤±ï¼šL_total = L_unsup + L_sup + L_tv")
# æ„å»ºåŸºäºçŸ«æ­£å­æ³¢çš„å·ç§¯ç®—å­
print("ğŸ”§ æ„å»ºForwardNetçŸ«æ­£åçš„å­æ³¢çš„å·ç§¯ç®—å­...")
nz = S_obs_batch.shape[2]
S = torch.diag(0.5 * torch.ones(nz - 1), diagonal=1) - torch.diag(0.5 * torch.ones(nz - 1), diagonal=-1)
S[0] = S[-1] = 0
WW = pylops.utils.signalprocessing.convmtx(wav_learned_smooth/wav_learned_smooth.max(), size, len(wav_learned_smooth) // 2)[:size]
WW = torch.tensor(WW, dtype=torch.float32, device=device)
WW = WW @ S.to(device)
PP = torch.matmul(WW.T, WW) + epsI * torch.eye(WW.shape[0], device=device) ##æœ€å°äºŒä¹˜è§£çš„ToplitzçŸ©é˜µçš„è£…ç½®

print(f"âœ… é˜¶æ®µ2å®Œæˆï¼šUNeté˜»æŠ—åæ¼”è®­ç»ƒ")
# ä¿å­˜Forwardç½‘ç»œï¼ˆå­æ³¢çŸ«æ­£å™¨ï¼‰
forward_save_path= os.path.join(model_save_dir, 'forward_net_wavelet_learned.pth')
torch.save(forward_net.state_dict(), forward_save_path)

# åˆå§‹åŒ–é˜¶æ®µ2çš„lossè®°å½•åˆ—è¡¨
stage2_total_loss = []
stage2_sup_loss = []
stage2_unsup_loss = []
stage2_tv_loss = []

threads_inference=[]  # ç”¨äºå­˜å‚¨æ¨ç†çº¿ç¨‹

for i in range(config['stage2_epoch_number']):
    epoch_loss = 0
    epoch_loss_sup = 0
    epoch_loss_unsup = 0
    epoch_loss_tv = 0
    batch_count = 0
    for S_obs_batch, Z_full_batch, Z_back_batch, M_mask_batch in train_loader:
        optimizer.zero_grad()
        # æ­¥éª¤1ï¼šæœ€å°äºŒä¹˜åˆå§‹åŒ–
        datarn = torch.matmul(WW.T, S_obs_batch - torch.matmul(WW, Z_back_batch))
        x, _, _, _ = torch.linalg.lstsq(PP[None, None], datarn)
        Z_init = x + Z_back_batch  # åŠ å›ä½é¢‘èƒŒæ™¯
        Z_init = (Z_init - Z_init.min()) / (Z_init.max() - Z_init.min())  # å½’ä¸€åŒ–
        # æ­¥éª¤2ï¼šUNetæ®‹å·®å­¦ä¹ 
        Z_pred = net(torch.cat([Z_init, S_obs_batch], dim=1)) + Z_init
        # ä¸‰é¡¹æŸå¤±å‡½æ•°è®¡ç®—
        # 1. äº•çº¦æŸæŸå¤±ï¼ˆå·®å¼‚åŒ–ç›‘ç£ï¼‰
        loss_sup = config['sup_coeff'] * mse(
            M_mask_batch * Z_pred, 
            M_mask_batch * Z_full_batch
        ) * Z_full_batch.shape[3] / 3
        # 2. ç‰©ç†çº¦æŸæŸå¤±ï¼ˆæ­£æ¼”ä¸€è‡´æ€§ï¼‰
        pred_reflection = DIFFZ(Z_pred)
        pred_seismic, _ = forward_net(
            pred_reflection, 
            torch.tensor(wav0[None, None, :, None], device=device)  # å§‹ç»ˆç”¨åˆå§‹å­æ³¢åšæ­£æ¼”ä¸€è‡´æ€§
        )
        loss_unsup =  config['unsup_coeff']* mse(pred_seismic, S_obs_batch)
        # 3. æ€»å˜åˆ†æ­£åˆ™åŒ–æŸå¤±ï¼ˆç©ºé—´å¹³æ»‘æ€§ï¼‰
        loss_tv = config['tv_coeff']* tv_loss(Z_pred, 1.0)
        # æ€»æŸå¤±
        total_loss = loss_unsup + loss_tv + loss_sup
        total_loss.backward()
        torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=1)
        optimizer.step()
        scheduler.step()
        epoch_loss += total_loss.item()
        epoch_loss_sup += loss_sup.item()
        epoch_loss_unsup += loss_unsup.item()
        epoch_loss_tv += loss_tv.item()
        batch_count += 1
    
    # è®°å½•æ¯ä¸ªepochçš„å¹³å‡æŸå¤±
    avg_total = epoch_loss / batch_count
    avg_sup = epoch_loss_sup / batch_count
    avg_unsup = epoch_loss_unsup / batch_count
    avg_tv = epoch_loss_tv / batch_count
    
    stage2_total_loss.append(avg_total)
    stage2_sup_loss.append(avg_sup)
    stage2_unsup_loss.append(avg_unsup)
    stage2_tv_loss.append(avg_tv)
    
    if i % 10 == 0:
        print(f"   Epoch {i:04d}/{config['stage2_epoch_number']:04d}")
        print(f"      æ€»æŸå¤±: {avg_total:.6f}")
        print(f"      äº•çº¦æŸæŸå¤±: {avg_sup:.6f} (é«˜å¯ä¿¡åº¦åŒºåŸŸåŒ¹é…)")
        print(f"      ç‰©ç†çº¦æŸæŸå¤±: {avg_unsup:.6f} (æ­£æ¼”ä¸€è‡´æ€§)")
        print(f"      TVæ­£åˆ™åŒ–æŸå¤±: {avg_tv:.6f} (ç©ºé—´å¹³æ»‘æ€§)")
        model_save_path = os.path.join(model_save_dir, f'Uet_TV_IMP_7labels_channel3_epoch={i}.pth')
        torch.save(net.state_dict(), model_save_path)
        print(f"ğŸ’¾ UNetæ¨¡å‹å·²ä¿å­˜: {model_save_path}")
        test_save_dir= os.path.join(save_dir, 'test', f'test_epoch={i}')
        thread=run_test.inference(model_path1=forward_save_path, model_path2=model_save_path, folder_dir=test_save_dir)
        threads_inference.append(thread)

# ä¿å­˜é˜¶æ®µ2çš„lossæ•°æ®
save_stage2_loss_data(save_dir, stage2_total_loss, stage2_sup_loss, 
                        stage2_unsup_loss, stage2_tv_loss)

# ä¿å­˜å®Œæ•´è®­ç»ƒè¿‡ç¨‹losså¯¹æ¯”å›¾
save_complete_training_loss(save_dir, total_lossF, stage2_total_loss, 
                            stage2_sup_loss, stage2_unsup_loss, stage2_tv_loss, 
                            )


print(f"ğŸ’¾ ForwardNet(å­æ³¢çŸ«æ­£å™¨)å·²ä¿å­˜: {forward_save_path}")
print(f"   è¯´æ˜ï¼šForwardNetåŒ…å«è®­ç»ƒæ—¶å­¦ä¹ çš„çŸ«æ­£å­æ³¢å‚æ•°")

for thread in threads_inference:
    thread.join()  # ç­‰å¾…æ‰€æœ‰æ¨ç†çº¿ç¨‹å®Œæˆ

